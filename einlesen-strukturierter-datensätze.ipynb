{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "# Metadaten / meta data\n",
        "title: \"Methodenbaustein Einlesen strukturierter Datensätze\"\n",
        "author:\n",
        "  - Lukas Arnold\n",
        "  - Simone Arnold\n",
        "  - Florian Bagemihl\n",
        "  - Matthias Baitsch\n",
        "  - Marc Fehr\n",
        "  - Maik Poetzsch\n",
        "  - Sebastian Seipel\n",
        "date: today # \"2024-03-05\" Jahr-Monat-Tag / year-month-day\n",
        "\n",
        "## Spracheinstellungen / language settings\n",
        "lang: de\n",
        "language:\n",
        "  de:\n",
        "    crossref-imp-title: \"Definition\"\n",
        "    crossref-imp-prefix: \"Definition\"\n",
        "    crossref-lst-title: \"Code-Block\"\n",
        "    crossref-lst-prefix: \"Code-Block\"\n",
        "    crossref-nte-title: \"Beispiel\"\n",
        "    crossref-nte-prefix: \"Beispiel\"\n",
        "    crossref-tip-title: \"Tipp\"\n",
        "    crossref-tip-prefix: \"Tipp\"\n",
        "    crossref-wrn-title: \"Hinweis\"\n",
        "    crossref-wrn-prefix: \"Hinweis\"\n",
        "\n",
        "## Formatoption / formating options\n",
        "format:\n",
        "  html:\n",
        "    default-image-extension: svg\n",
        "    code-copy: true # hover is default\n",
        "#  pdf:\n",
        "#    cite-method: biblatex\n",
        "#    biblio-title: Quellen\n",
        "#    default-image-extension: pdf # Vektorgrafiken werden als PDF eingebunden / vector grafics are embedded as PDF\n",
        "execute:\n",
        "  cache: false # remove when document is finished as cache: true can cause issues from time to time\n",
        "\n",
        "## Inhaltsverzeichnis / table of contents\n",
        "toc: true\n",
        "number-sections: true\n",
        "number-depth: 2\n",
        "\n",
        "## Bibliographie / bibliography\n",
        "bibliography: bibliography.bib\n",
        "biblio-style: authoryear\n",
        "\n",
        "## Objekteinstellungen / object options\n",
        "cap-location: bottom\n",
        "fig-align: center\n",
        "\n",
        "### Grafiken von R oder Matplotlib / Figures from R or Matplotlib\n",
        "# Empfehlung von / suggestion from https://r4ds.hadley.nz/quarto#sec-figures\n",
        "# fig-width: 6\n",
        "# fig-asp: 0.618\n",
        "---"
      ],
      "id": "e9b33303"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.border #Lizenz}\n",
        "\n",
        ":::: {layout=\"[20, 80]\"}\n",
        "![](skript/00-bilder/CC-BY.svg){fig-alt=\"Symbol des Lizenzhinweises Creative Commons BY\"}\n",
        "\n",
        "Bausteine Computergestützter Datenanalyse von Lukas Arnold, Simone Arnold, Florian Bagemihl, Matthias Baitsch, Marc Fehr, Maik Poetzsch und Sebastian Seipel. Methodenbaustein Einlesen strukturierter Datensätze von Maik Poetzsch ist lizensiert unter [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.de). Das Werk ist abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze). Ausgenommen von der Lizenz sind alle Logos und anders gekennzeichneten Inhalte. 2024\n",
        "\n",
        "::::\n",
        "\n",
        "Zitiervorschlag\n",
        "\n",
        "Arnold, Lukas, Simone Arnold, Matthias Baitsch, Marc Fehr, Maik Poetzsch, und Sebastian Seipel. 2024. „Bausteine Computergestützter Datenanalyse. Methodenbaustein Einlesen strukturierter Datensätze“. <https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze>.\n",
        "\n",
        "BibTeX-Vorlage\n",
        "\n",
        "```\n",
        "@misc{BCD-m-einlesen-strukturierter-datensätze-2024,\n",
        " title={Bausteine Computergestützter Datenanalyse. Methodenbaustein Einlesen strukturierter Datensätze},\n",
        " author={Arnold, Lukas and Arnold, Simone and Baitsch, Matthias and Fehr, Marc and Poetzsch, Maik and Seipel, Sebastian},\n",
        " year={2024},\n",
        " url={https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze}} \n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "{{< pagebreak >}}\n",
        "\n",
        "# Voraussetzungen\n",
        "Die Bearbeitungszeit dieses Bausteins beträgt circa **Platzhalter**. Für die Bearbeitung dieses Bausteins werden folgende Bausteine vorausgesetzt und die genannten Bibliotheken verwendet:\n",
        "\n",
        "- Werkzeugbaustein Python\n",
        "\n",
        "  - Modul os\n",
        "\n",
        "  - Modul Pandas\n",
        "\n",
        "    - openpyxl `pip install openpyxl`\n",
        "\n",
        "  - Modul Matplotlib\n",
        "\n",
        "Im Baustein werden **XY** Daten verwendet.\n",
        "\n",
        "Querverweis auf:\n",
        "\n",
        "  - w-NumPy\n",
        "\n",
        "  - w-Pandas\n",
        "\n",
        "# Lernziele\n",
        "In diesem Baustein lernen Sie ...\n",
        "\n",
        "- Datensätze unterschiedlicher Struktur und Formate einzulesen, zu bearbeiten und zu speichern. \n",
        "\n",
        "- den Unterschied zwischen identifizierenden und gemessenen Variablen kennen sowie Datensätze ins long- und wide-Format zu konvertieren.\n",
        "\n",
        "- das System tidy data kennen.\n",
        "\n",
        "- typische Probleme beim Einlesen von Datensätzen und Strategien zu deren Lösung kennen.\n",
        "\n",
        "\n",
        "\n",
        "# Einleitung\n",
        "\n",
        "2016 stellte eine Studie fest, dass ein Fünftel aller wissenschaftlichen Artikel im Bereich der Genetik auf der Grundlage von durch die Tabellenkalkulation Excel verfälschten Daten durchgeführt wurde [@Ziemann-2016]. Genbezeichnungen wie \"MARCH1\" wurden fälschlicherweise in ein Datumsformat umgewandelt. 2021 wurde diese Schätzung des Anteils betroffener Arbeiten sogar auf 30 Prozent angehoben. ([heise online](https://www.heise.de/news/Excel-wandelt-Genbezeichnungen-in-Datumsangaben-um-Problem-groesser-als-gedacht-6165902.html))\n",
        "\n",
        "Am Beginn der computergestützten Datenanalyse steht das Einlesen von Daten aus Dateien. In der Praxis ist das Einlesen von Daten alles andere als trivial. Daten werden in einer Vielzahl von Dateiformaten gespeichert. Deshalb ist es in der Datenanalyse erforderlich, mit verschiedenen Dateiformaten umgehen zu können: mit wenigen Kilobyte großen Textdateien, offenen und proprietären Formaten gängiger Büroanwendungen und mehreren hundert Megabyte großen Dateien in speziell für den Austausch wissenschaftlicher Daten entwickelten Formaten. Programmiersprachen wie Python und R bringen verschiedene Werkzeuge zum Lesen, Bearbeiten und Speichern von verschiedenen Dateiformaten mit. Spezialisierte Pakete ergänzen den Werkzeugkasten.\n",
        "\n",
        "Die praktischen Herausforderungen der Datenanalyse beschränken sich jedoch nicht nur auf technische Aspekte. Oftmals bereitet der innere Aufbau von Datensätzen die größten Schwierigkeiten. Ein wichtiger Bestandteil des Einlesens strukturierter Datensätze besteht darin, Fehler im Datensatz zu suchen und ggf. zu bereinigen. Dasu und Johnson schreiben: \n",
        "\n",
        "::: {.border layout=\"[5, 90, 5]\"}\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "\"Unfortunately, the data set is usually dirty, composed of many tables, and has unknown properties. Before any results can be produced, the data must be cleaned and explored—often a long and\n",
        "difficult task. [...] In our experience, the tasks of exploratory data mining and data cleaning constitute 80% of the effort that determines 80% of the value of the ultimate data\n",
        "mining results.\" (@Dasu-Johnson-2003, S. ix)\n",
        "\n",
        "&nbsp;\n",
        "\n",
        ":::\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Das Einlesen strukturierter Datensätze umfasst somit den gesamten Prozess des technischen Zugriffs auf Dateien, der Organisation, Fehlersuche und -korrektur sowie des Abspeicherns der Daten in einer für die weitere Bearbeitung geeigneten Form.\n",
        "\n",
        "In der praktischen Datenanalyse helfen zwei einfache Tipps beim Einlesen strukturierter Datensätze:\n",
        "\n",
        "::: {#tip-editor .callout-tip collapse=\"false\"}\n",
        "**Schauen Sie sich Ihre Daten an, bevor Sie diese mit Python einlesen!** Dafür reicht häufig ein gewöhnlicher Texteditor oder ein Tabellenkalkulationsprogramm. Ein kurzer Blick genügt, um die verwendeten Zeichentrenner, Tausendertrennzeichen, Datumsformate, die Kodierung fehlender Werte und die Unicode-Kodierung (wie UTF-8) zu identifizieren.\n",
        ":::\n",
        "  \n",
        "Dies ist aber nicht immer möglich, beispielsweise wenn Ihr Datensatz aus hunderten Spalten und Zehntausenden Zeilen besteht. Dieser Baustein vermittelt deshalb die Handwerkszeuge, um Datensätze ausschließlich mit den in Python verfügbaren Mitteln einzulesen.\n",
        "\n",
        "Es ist nicht erforderlich, die Besonderheiten aller hier vorgestellten Pakete und Funktionen auswendig zu beherrschen. Dafür ist das Themenfeld zu komplex und nicht selten ändert sich das Verhalten von Funktionen mit der weiterentwicklung der Programmiersprache. Die hier vorgestellten Besonderheiten von Funktionen sollten Sie allerdings einmal gehört haben, um einen mentalen Anknüpfungspunkt zu haben, wenn Sie in der Praxis auf Probleme stoßen.\n",
        "\n",
        "::: {#tip-dokumentation .callout-tip collapse=\"false\"}\n",
        "**Benutzen Sie die Dokumentation!** Auf diese Weise erhalten Sie einen vollständigen Überblick über standardmäßig gesetzten und optional verfügbaren Parameter. Außerdem erkennen Sie Änderungen in der Programmausführung und vermeiden so unerwartete Fehler.\n",
        "\n",
        ":::: {layout=\"[1, 1]\"}\n",
        "\n",
        "![Neuerung in Python](skript/00-bilder/added-in-pyhton.png){fig-alt=\"Hinweis auf eine Neuerung in Python\"}\n",
        "\n",
        "![Abkündigung in Python](skript/00-bilder/deprecated-in-python.png){fig-alt=\"Hinweis auf eine Abkündigung in Python\"}\n",
        "\n",
        "::::\n",
        "\n",
        ":::\n",
        "\n",
        "# Grundlagen: Merkmale von Datensätzen\n",
        "Bevor wir uns mit den praktischen Herausforderungen des Einlesens strukturierter Datensätze beschäftigten, werden zunächst einige Merkmale von Datensätzen behandelt, um ein grundlegendes Verständnis der Begrifflichkeiten zu schaffen und den Umgang der in der Basis von Python enthaltenen Werkzeuge zu vermitteln.\n",
        "\n",
        "::: {#imp-Datensatz .callout-important}\n",
        "## Datensatz\n",
        "\n",
        "Ein Datensatz ist eine Sammlung zusammengehöriger Daten. Datensätze enthalten einer oder mehreren Variablen zugeordnete Werte. Jeder Datensatz besitzt ein technisches Format, eine Struktur, mindestens eine Variable und mindestens einen Wert.\n",
        "\n",
        ":::\n",
        "\n",
        "## Technisches Format\n",
        "Das technische Format eines Datensatzes gibt vor, mit welchen Mitteln Daten eingelesen, bearbeitet und gespeichert werden können. Einige Beispiele sind:\n",
        "\n",
        "  - Druckerzeugnis, z. B. Telefonbuch: manuelles Ablesen von Name und Telefonnummer, irreversible Bearbeitung per Stift\n",
        "  \n",
        "  - Lochkarte, z. B. Parkschein: Lesegerät erkennt Lochung und gewährt eine Freistunde, irreversible Bearbeitung mit Stanzgerät\n",
        "  \n",
        "  - Textdatei, z. B. Einwohnerzahl nach Bundesländern: Kann mit einer Vielzahl von Computerprogrammen wie Texteditor, Tabellenkalkulationsprogramm oder Programmierumgebung eingelesen, bearbeitet und gespeichert werden.\n",
        "  \n",
        "  - Hierarchical Data Format HDF5, z. B. räumliche Daten zur Blitzdichte: benötigt spezialisierte Programme oder Pakete\n",
        "\n",
        "## Struktur\n",
        "Datensätze speichern Daten in einer definierten n-dimensionalen Struktur.\n",
        "\n",
        "::: {.border}\n",
        "![n-dimensionale Datensätze](skript/00-bilder/slicing_mf_mp.png){fig-alt=\"Dargestellt sind von links nach rechts ein-, zwei- und dreidimensionale Blockstrukturen, die Datensätze repräsentieren. Die Teilgrafiken werden in den folgenden Abschnitten wiederverwendet und dabei auch näher beschrieben.\"}\n",
        "\n",
        "slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). 2024\n",
        ":::\n",
        "\n",
        "### Eindimensionale Datensätze\n",
        "Die einfachste Form sind eindimensionale Datensätze, die Werte einer einzigen Variablen zuordnen. Eindimensionale Datensätze mit Werten des gleichen Typs (bspw. Zahlen) werden **Vektor** genannt. Eindimensionale Datensätze, die unterschiedliche Datentypen enthalten können, heißen **Liste**. Eindimensionale Datensätze verfügen lediglich über eine Achse: den Index, über den Elemente angesprochen werden können.\n",
        "\n",
        "::: {.border}\n",
        "\n",
        "![eindimensionale Datensätze](skript/00-bilder/eindimensionaler-datensatz-slicing-mf-mp.png){width=\"50%\" fig-alt=\"Dargestellt ist ein in fünf Blöcke unterteilter Streifen, der einen eindimensionalen Datensatz repräsentiert. Die Blöcke sind entlang der 0. Achse von links nach rechts mit 0 bis 4 beschriftet. Von Block Null aus geht ein blauer Pfeil zu Block drei, der blau markiert ist.\"}\n",
        "\n",
        "slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024\n",
        ":::\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Beispiele eindimensionaler Datensätze sind ein Einkaufszettel oder die Urliste eines Würfelexperiments. Über den Index kann beispielsweise das Würfelergebnis an der Indexposition 2 ausgegeben werden.\n"
      ],
      "id": "663a8dda"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print( *( Augen := [6, 2, 1, 2] ) )\n",
        "\n",
        "print(f\"Das Würfelergebnis an Indexposition 2 lautet: {Augen[2]}\")"
      ],
      "id": "5e67ca44",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eindimensionale Daten einlesen mit Python\n",
        "Maya und Hans haben je sechs Mal einen Würfel geworfen und ihre Wurfergebnisse in einer .txt-Datei protokolliert. Wir wollen mit die Dateien mit Python auswerten, um zu bestimmen, wer von beiden in Summe die höchste Augenzahl erreicht hat.\n",
        "\n",
        "| Daten | Dateiname |\n",
        "|---|------|\n",
        "| Würfelergebnisse Maya | dice-maya.txt |\n",
        "| Würfelergebnisse Hans | dice-hans.txt|\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "::: {.border}\n",
        "\n",
        "Um mit Python auf eine Datei zuzugreifen, muss diese fürs Lesen oder Schreiben geöffnet werden. Dazu wird in Python die Funktion [open](https://docs.python.org/3/library/functions.html#open) verwendet. Diese nimmt zwei Argumente, den Pfad der Datei und den Zugriffsmodus, an und liefert ein [Dateiobjekt](https://docs.python.org/3/glossary.html#term-file-object) zurück. Aus dem Dateiobjekt werden dann die Inhalte der Datei ausgelesen.\n",
        "\n",
        "#### Dateipfad\n",
        "Der lokale Dateipfad wird ausgehend vom aktuellen Arbeitsverzeichnis angegeben."
      ],
      "id": "e6e87492"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pfad_maya = \"skript/01-daten/dice-maya.txt\"\n",
        "pfad_hans = \"skript/01-daten/dice-hans.txt\""
      ],
      "id": "941d73c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::: {#tip-wd-Python .callout-tip collapse=\"false\"}\n",
        "## Arbeitsverzeichnis in Python ermitteln und wechseln\n",
        "Der Pfad des aktuellen Arbeitsverzeichnisses kann mit dem Modul os mittels `os.getcwd()` ermittelt werden (hier ohne Ausgabe). Mit `os.chdir('neuer_pfad')` kann das Arbeitsverzeichnis ggf. gewechselt werden. Die korrekte Formatierung des Pfads erkennen Sie an der Ausgabe von `os.getcwd()`."
      ],
      "id": "a530e690"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: false\n",
        "\n",
        "import os\n",
        "print(os.getcwd())"
      ],
      "id": "d95365c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::::\n",
        "\n",
        "#### Zugriffsmodus\n",
        "Als Zugriffsmodus stehen unter anderem folgende Optionen zur Verfügung:\n",
        "\n",
        "| Modus | Beschreibung |\n",
        "| --- | ----------- |\n",
        "| `r` | lesender Zugriff |\n",
        "| `w` | Schreibzugriff, Datei wird überschrieben |\n",
        "| `x` | Erzeugt die Datei, Fehlermeldung, wenn die Datei bereits existiert |\n",
        "| `a` | Schreibzugriff, Inhalte werden angehängt |\n",
        "| `b` | Binärmodus (z. B. für Grafiken) |\n",
        "| `t` | Textmodus, default|\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Die Zugriffsmodi können auch kombiniert werden. Weitere Informationen dazu finden Sie in der [Dokumentation](https://docs.python.org/3/library/functions.html#open). Sofern nicht im Binärmodus auf Dateien zugegriffen wird, liefert die Funktion `open()` den Dateiinhalt als string zurück. \n",
        "\n",
        "Im Lesemodus wird ein Datenobjekt erzeugt. "
      ],
      "id": "1672b876"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "daten_maya = open(pfad_maya, mode = 'r')\n",
        "print(daten_maya)"
      ],
      "id": "2019eaa6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn das Datenobjekt `daten_maya` der Funktion `print()` übergeben wird, gibt Python die Klasse des Objekts zurück, in diesem Fall also _io.TextIOWrapper. Diese Klasse stammt aus dem Modul io und ist für das Lesen und Schreiben von Textdateien zuständig. Ebenfalls werden der Dateipfad, der Zugriffsmodus und die Enkodierung der Datei ausgegeben. Sollte die Enkodierung nicht automatisch als UTF-8 erkannt werden, kann diese mit dem Argument `encoding = 'UTF-8'` übergeben werden. "
      ],
      "id": "c379ec56"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "daten_maya = open(pfad_maya, mode = 'r', encoding = 'UTF-8')\n",
        "print(daten_maya)"
      ],
      "id": "5030f993",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Attribute der Datei können mit entsprechenden Befehlen abgerufen werden."
      ],
      "id": "cb0f07e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Dateipfad: {daten_maya.name}\\n\"\n",
        "      f\"Dateiname: {os.path.basename(daten_maya.name)}\\n\"\n",
        "      f\"Datei ist geschlossen: {daten_maya.closed}\\n\"\n",
        "      f\"Zugriffsmodus: {daten_maya.mode}\")\n"
      ],
      "id": "a9bfd7c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Daten ausgeben\n",
        "Um den Dateiinhalt auszugeben, kann das Datenobjekt mit einer Schleife zeilenweise durchlaufen und ausgegeben werden. (Die Datei dice-maya hat nur eine Zeile.) "
      ],
      "id": "84b5c3ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "i = 0\n",
        "for zeile in daten_maya:\n",
        "    print(f\"Inhalt Zeile {i}, mit {len(zeile)} Zeichen:\")\n",
        "    print(zeile)\n",
        "    i += 1"
      ],
      "id": "1358acba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dies ist jedoch für größere Dateien nicht sonderlich praktikabel. Die Ausgabe einzelner Zeilen mit der Funktion `print()` kann aber nützlich sein, um die genaue Formatierung der Zeichenkette zu prüfen. In diesem Fall hat Maya ihre Daten in Anführungszeichen gesetzt und mit einem Komma voneinander getrennt.\n",
        "\n",
        ":::: {#tip-zeilenweise .callout-tip collapse=\"false\"}\n",
        "## Daten kontrollieren\n",
        "\n",
        "Beim Einlesen goßer Datensätze sollten nicht nur die erste(n) Zeile(n) des Datensatzes, sondern auch Ausschnitte aus der Mitte und dem Ende kontrolliert werden. Dies hilft, Fehler etwa bei der Umwandlung von Dezimal- und Tausendertrennzeichen, des Datumsformats oder eine unerwartete Anzahl fehlender Werte und sonstige Auffälligkeiten zu identifizieren.\n",
        "\n",
        "::::\n",
        "\n",
        "#### Daten einlesen\n",
        "Um den gesamten Inhalt einer Datei einzulesen, kann die Methode [datenobjekt.read()](https://docs.python.org/3/tutorial/inputoutput.html) verwendet werden. Die Methode hat als optionales Argument `.read(size)`. size wird als Ganzzahl übergeben und entsprechend viele Zeichen (im Binärmodus entsprechend viele Bytes) werden ggf. bis zum Dateiende ausgelesen."
      ],
      "id": "014f42a5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "augen_maya = daten_maya.read()\n",
        "\n",
        "print(f\"len(augen_maya): {len(augen_maya)}\\n\\n\"\n",
        "      f\"Inhalt der Datei augen_maya:\\n{augen_maya}\")"
      ],
      "id": "19a1d87a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Das hat offensichtlich nicht geklappt, der ausgelesene Dateiinhalt ist leer! Der Grund dafür ist, dass beim Lesen (und beim Schreiben) einer Datei der Dateizeiger die Datei durchläuft. Nachdem die Datei daten_maya im Abschnitt \"Daten ausgeben\" zeilenweise ausgegeben wurde, steht der Dateizeiger am Ende der Datei.\n",
        "\n",
        ":::: {#wrn-Dateizeiger .callout-warning appearance=\"simple\"}\n",
        "## Dateizeiger in Python\n",
        "\n",
        "Wird eine Datei zeilenweise oder mit der Methode `.read()` ausgelesen, wird der Dateizeiger um die angegebene Zeichenzahl bzw. bis ans Ende der Datei bewegt. Wird beispielsweise ein Datensatz 'daten' geöffnet und mit der Methode `daten.read(3)` die ersten drei Zeichen ausgelesen, bewegt sich der Dateizeiger von der Indexposition 0 zur Indexposition 3 (bzw. steht jeweils davor).\n",
        "\n",
        "::::: {#fig-Dateizeiger layout-ncol=2}\n",
        "\n",
        "![](skript/00-bilder/indexposition-0.png){fig-alt=\"Dargestellt ist ein in fünf Blöcke unterteilter Streifen, der einen eindimensionalen Datensatz repräsentiert. Die Blöcke sind entlang der 0. Achse von links nach rechts mit 0 bis 4 beschriftet. Oberhalb steht links vom Block Null ein Pfeil mit der Beschriftung Indexposition Null\"}\n",
        "\n",
        "![](skript/00-bilder/indexposition-3.png){fig-alt=\"Dargestellt ist der gleiche Streifen. Oberhalb steht links vom Block drei ein Pfeil mit der Beschriftung Indexposition drei\"}\n",
        "\n",
        "Bewegung des Dateizeigers beim Auslesen von drei Zeichen\n",
        ":::::\n",
        "\n",
        "Die Methode `daten.tell()` gibt zurück, an welcher Position sich der Dateizeiger befindet.\n",
        "\n",
        "Mit der Methode `daten.seek(offset, whence = 0)` wird der Zeiger an eine bestimmte Position gesetzt. Die Methode akzeptiert das Argument offset (Versatz) und das optionale Argument whence (woher), dessen Standardwert 0 (Dateianfang) ist. Für Zugriffe **im Binärmodus** (`open(pfad, mode = 'rb')`) kann das Argument whence außerdem die Werte 1 (aktuelle Position) oder 2 (Dateiende) annehmen.\n",
        "\n",
        "  * `daten.seek(0, 0)` bezeichnet den Dateianfang\n",
        "\n",
        "  * `daten.seek(0, 1)` bezeichnet die aktuelle Position in der Datei\n",
        "\n",
        "  * `daten.seek(0, 2)` bezeichnet das Dateiende\n",
        "\n",
        "  * `daten.seek(-3, 2)` bezeichnet das dritte Zeichen vor dem Dateiende\n",
        "\n",
        "::::\n",
        "\n",
        "Wird der Dateizeiger mit der Methode `datenobjekt.seek(0)` an den Dateianfang gestellt, gelingt das Auslesen der Datei."
      ],
      "id": "2ed9f05a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hold"
      },
      "source": [
        "print(f\"Position des Dateizeigers vor dem Zurücksetzen auf 0: {daten_maya.tell()}\")\n",
        "\n",
        "daten_maya.seek(0);\n",
        "print(f\"Position des Dateizeigers nach dem Zurücksetzen auf 0: {daten_maya.tell()}\")\n",
        "\n",
        "augen_maya = daten_maya.read()\n",
        "\n",
        "print(f\"Inhalt des Objekts augen_maya:\\n{augen_maya}\")"
      ],
      "id": "9f15c2fc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Geben Sie aus dem Datenobjekt daten_maya mit den Methoden .seek() und .read() die Zahlen and zweiter und dritter Stelle, also 6 und 2, aus.**\n",
        "\n",
        ":::: {#tip-Musterlösung-Zeigerposition .callout-tip collapse=\"true\"}\n",
        "## Musterlösung Dateizeiger bewegen"
      ],
      "id": "7c53ab36"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "daten_maya.seek(6, 0);\n",
        "print(daten_maya.read(1))\n",
        "\n",
        "daten_maya.seek(daten_maya.tell() + 4, 0);\n",
        "print(daten_maya.read(1))"
      ],
      "id": "ee82b64b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::::\n",
        "\n",
        "Um Mayas Würfelergebnisse zu addieren, müssen die Zahlen extrahiert und in Ganzzahlen umgewandelt werden, da im Textmodus stets strings zurückgegeben werden."
      ],
      "id": "d760c510"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(type(augen_maya))"
      ],
      "id": "21ed1dc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dazu werden mit der Methode `str.strip(\")` das führende und abschließende Anführungszeichen entfernt sowie anschließend mit der Methode `str.split('\", \"')` der String in eine Liste aufgeteilt. Anschließend werden die Listenelemente in Ganzzahlen umgewandelt und summiert."
      ],
      "id": "6882ae94"
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hold"
      },
      "source": [
        "print(f\"augen_maya:\\n{augen_maya}\")\n",
        "\n",
        "augen_maya = augen_maya.strip('\"')\n",
        "print(f\"\\naugen_maya.strip('\\\"'):\\n{augen_maya}\")\n",
        "\n",
        "augen_maya = augen_maya.split('\", \"')\n",
        "print(f\"\\naugen_maya.split('\\\", \\\"'):\\n{augen_maya}\")\n",
        "\n",
        "augen_maya_int = []\n",
        "for i in augen_maya:\n",
        "  augen_maya_int.append(int(i))\n",
        "\n",
        "print(f\"\\naugen_maya_int:\\n{augen_maya_int}\\n\\nSumme Augen: {sum(augen_maya_int)}\")"
      ],
      "id": "1669ae56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Datei schließen\n",
        "\n",
        "Nach dem Zugriff auf die Datei, muss diese wieder geschlossen werden, um diese für andere Programme freizugeben."
      ],
      "id": "d05b8274"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "daten_maya.close()"
      ],
      "id": "4ec3e9e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::: {#wrn-Schreiboperationen .callout-warning appearance=\"simple\"}\n",
        "# Schreiboperationen mit Python\n",
        "\n",
        "Das Schließen einer Datei ist besonders für Schreiboperationen auf Datenobjekten wichtig. Andernfalls kann es passieren, dass Inhalte mit `datenobjekt.write()` nicht vollständig auf den Datenträger geschrieben werden. Siehe dazu die [Dokumentation](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files).\n",
        "\n",
        "::::\n",
        "\n",
        "### Übung eindimensionale Datensätze\n",
        "\n",
        "**Welche Augenzahl hat Hans erreicht?**\n",
        "\n",
        "**Die Musterlösung kann Marc machen**\n",
        "\n",
        ":::: {#tip-Musterlösung-Augenzahlvergleich .callout-tip collapse=\"true\"}\n",
        "## Musterlösung Augenzahlvergleich\n",
        "Musterlösung von Marc\n",
        "\n",
        "::::\n",
        "\n",
        "[@Arnold-2023-funktionen-module-dateien]\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "### Zweidimensionale Datensätze\n",
        "Zweidimensionale Datensätze organisieren Werte in einer aus Zeilen und Spalten bestehenden **Matrix** oder einem **Dataframe**. Eine Matrix enthält nur einen Datentyp (bspw. Zahlen), ein Dataframe kann unterschiedliche Datentypen enthalten (bspw. Zahlen und Wahrheitswerte). In Python stellt das Modul Pandas die DataFrame-Struktur bereit. **hier Querverweis auf w-Pandas** \n",
        "\n",
        "::: {.border}\n",
        "![zweidimensionaler Datensatz](skript/00-bilder/zweidimensionaler-datensatz-slicing-mf-mp.png){width=\"45%\" fig-alt=\"Dargestellt ist ein zweidimensionaler Block, der einen zweidimensionalen Datensatz repräsentiert. Pfeile repräsentieren die zwei Achsen. Die nullte Achse entspricht der Länge (von oben nach unten) und die erste Achse der Breite des Datensatzes.\"}\n",
        "\n",
        "slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024\n",
        ":::\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Typischerweise entspricht in zweidimensionalen Datensätzen jede Spalte einer **Variablen** und jede Zeile einer **Beobachtung**. Variablen speichern alle Werte eines Merkmals, zum Beispiel des Würfelergebnisses. Beobachtungen speichern alle Werte, die für eine Beobachtungseinheit gemessen wurden, z. B. für eine Person. [@Wickham-2014, S. 3]\n"
      ],
      "id": "16eb83e5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "messung1 = pd.DataFrame({'Name': ['Hans', 'Elke', 'Jean', 'Maya'], 'Geburtstag': ['26.02.', '14.03.', '30.12.', '07.09.'], 'Würfelfarbe': ['rosa', 'rosa', 'blau', 'gelb'], 'Summe Augen': [17, 12, 8, 23]})\n",
        "\n",
        "messung1"
      ],
      "id": "f4f98826",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "&nbsp;\n",
        "\n",
        "Über die Angabe der Indizes entlang der 0. und der 1. Achse kann die Summe der gewürfelten Augen einer Person ausgegeben werden. \n"
      ],
      "id": "d9e93ce2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Jean würfelte {messung1.iloc[2, 3]} Augen\")"
      ],
      "id": "e627ec9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Es ist aber auch möglich, zunächst eine Spalte auszuwählen und dann wie bei einem eindimensionalen Datensatz den Wert an einer Indexposition aufzurufen.\n"
      ],
      "id": "f19a47e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Jean würfelte {messung1['Summe Augen'][2]} Augen\")"
      ],
      "id": "93bfe040",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### long- und wide-Format\n",
        "Zweidimensionale Datensätze werden zumeist in einer aus Zeilen und Spalten bestehenden Matrix dargestellt. Den zeilenweise eingetragenen Beobachtungen werden Werte für die in den Spalten organisierten Variablen zugeordnet. Diese Art Daten darzustellen, wird wide-Format genannt: Mit jeder zusätzlich gemessenen Variablen wird der Datensatz breiter.\n",
        "\n",
        "Eine andere Art Daten zu organisieren und über Daten nachzudenken, ist die Darstellung im long-Format. Einige Programme und Pakete erfordern Daten im long-Format oder profitieren zumindest davon beispielsweise bei der Erstellung von Grafiken. Schauen wir uns zunächst noch einmal den Datensatz messung1 im wide-Format an. Welche Beobachtungseinheiten gibt es? Welche Variablen wurden erhoben?\n"
      ],
      "id": "fe283c21"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "messung1"
      ],
      "id": "2b72b853",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "&nbsp;\n",
        "\n",
        "Vermutlich werden Sie davon ausgehen, dass die Beobachtungseinheiten Hans, Elke, Jean und Maya sind und die Variablen Geburtstag, Würfelfarbe und Summe Augen. Es ist aber auch denkbar, dass die Beobachtungseinheit Person mit 0, 1, 2 und 3 kodiert wurde (dem Zeilenindex des Datensatzes) und die Spalte Name ebenfalls eine der erhobenen Variablen ist. Ebenso könnte es nur zwei Variablen, Würfelfarbe und Summe Augen, geben, während die Spalten Name und Geburtstag die beobachteten Personen kodieren. Stellen Sie sich vor, es gäbe eine zweite Person mit dem Namen Hans. Dann könnten die Würfelergebnisse der Personen mit dem Namen Hans nur über den Geburtstag am 26.02. oder 11.11. korrekt zugeordnet werden.\n"
      ],
      "id": "b3b96f44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "messung1 = pd.DataFrame({'Name': ['Hans', 'Elke', 'Jean', 'Maya', 'Hans'], 'Geburtstag': ['26.02.', '14.03.', '30.12.', '07.09.', '11.11.'], 'Würfelfarbe': ['rosa', 'rosa', 'blau', 'gelb', 'rosa'], 'Summe Augen': [12, 17, 8, 23, 7]})\n",
        "\n",
        "messung1"
      ],
      "id": "9c425511",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "&nbsp;\n",
        "\n",
        "Das long-Format macht diese Überlegungen explizit, indem identifizierende Variablen (identification variables, kurz: id vars) und gemessene Variablen (measure variables, kurz: measure vars oder value vars) unterschieden werden. Die Transformation eines Datensatzes aus dem wide-Format ins long-Format wird melting (schmelzen) genannt. Das Modul Pandas bietet die Funktion `pd.melt(frame, id_vars = None)`. Diese erwartet einen DataFrame. Im optionalen Argument `id_vars` wird angegeben, welche Spalten die identifizierenden Variablen sind.\n"
      ],
      "id": "5b9b2ad4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "messung1_long = pd.melt(messung1, id_vars = ['Name', 'Geburtstag'])\n",
        "\n",
        "messung1_long"
      ],
      "id": "6dbf736a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "&nbsp;\n",
        "\n",
        "Im long-Format werden die gemessenen Variablen in der Spalte variable aufgeführt und deren Wert in der Spalte value eingetragen. Mit jeder zusätzlich erhobenen Variablen wird der Datensatz länger.\n",
        "\n",
        "Wenn Sie die Unterscheidung von identifizierenden und gemessenen Variablen zu Ende denken, kann der Variablenname selbst als eine identifizierende Variable für den Wert in der Spalte value aufgefasst werden. Ein Datensatz kann als eine Struktur verstanden werden, die genau eine gemessene Variable, nämlich value, und eine Anzahl identifizierender Variablen besitzt. Dies kann im long-Format wie folgt dargestellt werden.\n"
      ],
      "id": "92e4df12"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: false\n",
        "\n",
        "messung1_all_id = pd.melt(messung1, id_vars = ['Name', 'Geburtstag', 'Würfelfarbe'])\n",
        "\n",
        "messung1_all_id"
      ],
      "id": "7f3d30f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In dieser Darstellung wird beispielsweise der erste Wert 12 durch Name = Hans, Geburtstag = 26.02., Würfelfarbe = rosa und variable = Summe Augen identifiziert.\n",
        "\n",
        "\n",
        "::: {layout=\"[70, 30]\"}"
      ],
      "id": "a98d2e66"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "messung1_all_id = pd.melt(messung1, id_vars = ['Name', 'Geburtstag', 'Würfelfarbe'])\n",
        "\n",
        "messung1_all_id"
      ],
      "id": "cd1fbd04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](skript/00-bilder/5f489ffabc91dec1ec2192dc4e993e00.jpg){width=\"90%\"} \n",
        "\n",
        "<!-- wow kommt wieder weg ;-) -->\n",
        "\n",
        "::: \n",
        "\n",
        "**Was passiert, wenn auch die Variable `Summe Augen` dem Argument `id_vars` übergeben wird?**\n",
        "\n",
        "::: {#tip-Antwort-all-id .callout-tip collapse=\"true\"}\n",
        "## Antwort\n",
        "\n",
        "Der Befehl `messung1_all_id = pd.melt(messung1, id_vars = ['Name', 'Geburtstag', 'Würfelfarbe', 'Summe Augen'])` produziert einen leeren Dataframe, weil keine gemessenen Werte verbleiben.\n",
        ":::\n",
        "\n",
        "Auch der umgekehrte Fall ist möglich: Werden beim melting keine id_vars angegeben, werden alle Spalten als gemessene Variablen behandelt.\n"
      ],
      "id": "337fc3b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "messung1_no_id = pd.melt(messung1)\n",
        "\n",
        "messung1_no_id"
      ],
      "id": "3df29472",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "&nbsp;\n",
        "\n",
        "Die Umkehroperation zum melting wird casting (gießen) oder pivoting (schwenken) genannt. Dabei wird ein im long-Format vorliegender Datensatz in das wide-Format konvertiert. Die Pandas Funktion `pd.pivot(data, columns, index)` nimmt einen melted DataFrame entgegen und konveriert diesen aus den einzigartigen Werten in columns (= Spaltennamen des DataFrame im wide-Format) und den einzigartigen Werten in index (= Zeilenindex des DataFrame im wide-Format). Wird der Funktion keine Spalte für index übergeben, wird der bestehende Index des melted DataFrame verwendet (der mit 20 Zeilen natürlich viel zu lang ist.) Da das Objekt messung1_no_id keine geeignete Indexspalte besitzt, muss diese vor dem casting erzeugt werden. Dies ist mit der Methode `messung1_no_id.groupby('variable').cumcount()` möglich, die die Anzahl jeder Ausprägung in der übergebenen Spalte bei 0 beginnend durchzählt. (Ein direktes Ersetzen des Index ist auf diese Weise nicht möglich, da der Index des an `pd.pivot(data, columns, index)` übergebenen DataFrames keine Doppelungen enthalten darf.)\n"
      ],
      "id": "1db892f6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# pd.pivot() benötigt einen Index oder benutzt den bestehenden Index, des melted_df, der zu lang ist\n",
        "# Deshalb eine zusätzliche Spalte in messung1_no_id einfügen\n",
        "## einfach: messung1_no_id['new_index'] = list(range(0, 5)) * 4 \n",
        "## allgemein: messung1_no_id['new_index'] = messung1_no_id.groupby('variable').cumcount()\n",
        "\n",
        "# Spalte new_index einfügen\n",
        "messung1_no_id['new_index'] = messung1_no_id.groupby('variable').cumcount()\n",
        "print (f\"Der Datensatz im long-Format mit zusätzlicher Spalte new_index:\\n{messung1_no_id}\")\n",
        "\n",
        "# casting\n",
        "messung1_cast = pd.pivot(messung1_no_id, index = 'new_index', columns = 'variable', values = 'value')\n",
        "print(f\"\\nDer Datensatz im wide-Format:\\n{messung1_cast}\")"
      ],
      "id": "b1ec2eda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Das Ergebnis entspricht noch nicht dem ursprünglichen Datensatz im wide-Format. Um das Ausgangsformat wiederherzustellen, müssen die Spalten in die ursprüngliche Reihenfolge gebracht sowie der Index und dessen Beschriftung zurückgesetzt werden.\n"
      ],
      "id": "3597794b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Spalten anordnen, Index zurücksetzen\n",
        "messung1_cast = messung1_cast[['Name', 'Geburtstag', 'Würfelfarbe', 'Summe Augen']]\n",
        "messung1_cast.reset_index(drop = True, inplace = True)\n",
        "messung1_cast.rename_axis(None, axis = 1, inplace = True)\n",
        "\n",
        "print(f\"\\nDer Datensatz im wide-Format mit zurückgesetztem Index:\\n\\n{messung1_cast}\")"
      ],
      "id": "d60bfd0d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Übung zweidimensionale Datensätze\n",
        "Oben wurde das Objekt messung1_long mit dem Befehl `messung1_long = pd.melt(messung1, id_vars = ['Name', 'Geburtstag'])` angelegt.  \n",
        "**Benutzen Sie die Funktion** `df.cast()`, **um den Datensatz messung1 wieder ins wide-Format zu transformieren.**\n"
      ],
      "id": "c1db4fea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "messung1_long"
      ],
      "id": "738cd74f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {#tip-pivoting .callout-tip collapse=\"true\"}\n",
        "## Musterlösung zweidimensionale Datensätze\n"
      ],
      "id": "c02807e9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Spalte new_index einfügen\n",
        "messung1_long['new_index'] = messung1_long.groupby('variable').cumcount()\n",
        "\n",
        "# casting\n",
        "messung1_long_cast = pd.pivot(messung1_long, index = 'new_index', columns = 'variable', values = 'value')\n",
        "\n",
        "# Spalten anordnen, Index zurücksetzen\n",
        "messung1_long_cast = messung1_cast[['Name', 'Geburtstag', 'Würfelfarbe', 'Summe Augen']]\n",
        "messung1_long_cast.reset_index(drop = True, inplace = True)\n",
        "messung1_long_cast.rename_axis(None, axis = 1, inplace = True)\n",
        "\n",
        "messung1_long_cast"
      ],
      "id": "9b447cb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "### Drei- und mehrdimensionale Datensätze\n",
        "Drei- oder mehrdimensionale Datensätze organisieren komplexe Datenstrukturen in sogenannten **Arrays**. Arrays sind n-dimensionale Datenstrukturen und damit zugleich ein Oberbegriff. So ist eine Liste ein eindimensionales Array, eine Matrix ein zweidimensionales Array und eine Excel-Datei mit mehreren Arbeitsblättern für jährlich erhobene Umfragedaten ein 3-dimensionales Array (Arbeitsblätter, Zeilen, Spalten). Abhängig vom verwendeten Modul können Arrays ein oder mehrere Datentypen enthalten. **ggf. ergänzen: Modul xarray <https://docs.xarray.dev/en/stable/user-guide/pandas.html>**\n",
        "\n",
        "::: {.border}\n",
        "![dreidimensionale Datensätze](skript/00-bilder/dreidimensionaler-datensatz-slicing-mf-mp.png){width=\"50%\" fig-alt=\"Dargestellt ist ein dreidimensionaler Block, der einen dreidimensionalen Datensatz repräsentiert. Pfeile repräsentieren die drei Achsen. Die nullte Achse entspricht der Tiefe, die erste Achse der Länge (von oben nach unten) und die zweite Achse der Breite des Datensatzes.\"}\n",
        "\n",
        "slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024\n",
        "\n",
        ":::\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Für drei- und mehrdimensionale Datenstrukturen werden häufig spezialisierte Datenformate verwendet, die in den Folgenden Abschnitten behandelt werden. Dies hat unter anderem den Grund, dass so leichter verschiedene Datentypen verarbeitet und mit Metadaten (siehe @sec-metadaten) dokumentiert werden können.\n",
        "\n",
        "**optional: Exkurs JSON <https://docs.python.org/3/tutorial/inputoutput.html>**\n",
        "\n",
        "### Bilddaten einlesen\n",
        "\n",
        "::: {.border}\n",
        "Digitale Bilder liegen in Form eines dreidimensionalen Datensatzes vor. In Zeilen und Spalten liegen für jeden Pixel Farbwerte (Rot, Grün, Blau) und gegebenenfalls ein Alphawert vor (Rot, Grün, Blau, Alpha). Die Farbwerte liegen entweder im Bereich von 0 bis 1 oder von 0 bis 255 (8-Bit).\n",
        "\n",
        "```\n",
        "# Farbwerte für einen Pixel\n",
        "[Rotwert, Grünwert, Blauwert]\n",
        "\n",
        "# Eine Bildzeile mit drei Pixeln\n",
        "[[Rotwert, Grünwert, Blauwert], [Rotwert, Grünwert, Blauwert], [Rotwert, Grünwert, Blauwert]]\n",
        "\n",
        "# Ein Bild aus drei Zeilen und Spalten\n",
        "[[[Rotwert, Grünwert, Blauwert], [Rotwert, Grünwert, Blauwert], [Rotwert, Grünwert, Blauwert]],\n",
        "[[Rotwert, Grünwert, Blauwert], [Rotwert, Grünwert, Blauwert], [Rotwert, Grünwert, Blauwert]],\n",
        "[[Rotwert, Grünwert, Blauwert], [Rotwert, Grünwert, Blauwert], [Rotwert, Grünwert, Blauwert]]]\n",
        "```\n",
        "\n",
        "Bilddateien können mit der Funktion `plt.imread()` aus dem Modul `matplotlib.pyplot` eingelesen werden. \n",
        "\n",
        ":::: {.border}"
      ],
      "id": "58c2e881"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logo = plt.imread(fname = 'skript/00-bilder/python-logo-and-wordmark-cc0-tm.png')\n",
        "\n",
        "plt.imshow(logo)"
      ],
      "id": "2d0c4b44",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Python Logo von Python Software Foundation steht unter der [GPLv3](https://www.gnu.org/licenses/gpl-3.0.html). Die Wort-Bild-Marke ist markenrechtlich geschützt: <https://www.python.org/psf/trademarks/>. Das Werk ist abrufbar auf [wikimedia](https://de.m.wikipedia.org/wiki/Datei:Python_logo_and_wordmark.svg). 2008\n",
        "\n",
        ":::: \n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Die Struktur des Datensatzes kann mit dem Attribut `.shape` abgerufen werden.\n"
      ],
      "id": "50d307de"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(type(logo), \"\\n\")\n",
        "\n",
        "print(logo.shape)"
      ],
      "id": "184e47c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Daten wurden als NumPy.ndarray eingelesen. Das Logo hat 144 Zeilen, 486 Spalten und liegt im RGBA-Farbraum vor. Ein Ausschnitt der Daten sieht so aus:\n"
      ],
      "id": "5503acf0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(logo[50:52, 50:52, : ])"
      ],
      "id": "10778c45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Übung dreidimensionale Datensätze\n",
        "Über den Index der dritten Dimension können die Farbkanäle Rot, Grün und Blau ausgewählt und mit der Funktion `plt.imshow(cmap = 'Greys_r')` einzeln dargestellt werden. Das Argument `cmap = 'Greys_r'` weist die Funktion an, die invertierte Grauskala benutzen. Dadurch werden hohe Farbwerte hell und niedrige Farbwerte dunkel dargestellt. **Versuchen Sie es einmal.**\n",
        "\n",
        ":::: {#tip-logo .callout-tip collapse=\"true\"}\n",
        "## Musterlösung dreidimensionale Datensätze"
      ],
      "id": "e61dc113"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: Farbkanäle des Pythonlogos\n",
        "#| fig-alt: \"Dargestellt sind die drei Farbkanäle des Pythonlogos.\"\n",
        "\n",
        "kanal = [\"Rotkanal\", \"Grünkanal\", \"Blaukanal\"]\n",
        "\n",
        "plt.figure(figsize = (9, 6))\n",
        "\n",
        "for i in range(3):\n",
        "\n",
        "  plt.subplot(1, 4, i + 1)\n",
        "  plt.imshow(logo[ :, :, i], cmap = 'Greys_r')\n",
        "  plt.title(label = kanal[i])\n",
        "\n",
        "plt.colorbar(shrink = 0.15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "96972977",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Möglicherweise wundern Sie sich, warum der Bildhintergrund in jedem Farbkanal schwarz ist. Die Ursache finden Sie im nächsten Tipp.\n",
        "\n",
        "::::: {#tip-logo .callout-tip collapse=\"true\"}\n",
        "## Erklärung Bildhintergrund\n",
        "Der Bildhintergrund hat in allen Kanälen, auch im Alphakanal, den Farbwert 0. Dieser Teil des Bildes ist deshalb vollständig transparent und wird vom Hintergrund der Internetseite ausgefüllt. Der Bildhintergrund des Logos wirkt deshalb weiß.\n"
      ],
      "id": "a5563a0b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: Alphakanal des Pythonlogos\n",
        "#| fig-alt: \"Dargestellt ist der Alphakanal des Pythonlogos. Der Bildhintergrund hat den Farbwert 0.\"\n",
        "\n",
        "# Alphakanal\n",
        "plt.imshow(logo[ :, :, 3], cmap = 'Greys_r')\n",
        "plt.title(label = 'Alphakanal')\n",
        "plt.colorbar(shrink = 0.4)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Die ersten zwei Zeilen und Spalten des Logos\n",
        "print(logo[0:2, 0:2, : ])"
      ],
      "id": "57cc6746",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::::\n",
        "::::\n",
        "\n",
        "[@Arnold-2023-numpy-dateien]\n",
        "\n",
        ":::\n",
        "\n",
        "## Datentyp {#sec-datentyp}\n",
        "Der Datentyp gibt an, wie die in einem Datensatz einhaltenen Werte von Python interpretiert werden sollen. Beispielsweise kann der Wert \"1\" ein Zeichen, eine Ganzzahl, einen Wahrheitswert, den Monat Januar oder die Ausprägung einer kategorialen Variablen repräsentieren. Python unterstützt als vielseitig einsetzbare Programmiersprache zahlreiche Datentypen, die den Kategorien: numerics, sequences, mappings, classes, instances and exceptions zugeordnet sind. Nähere Informationen dazu finden Sie in der [Dokumentation](https://docs.python.org/3/library/stdtypes.html).\n",
        "\n",
        "::: {.border}\n",
        "![Datentypen in Python](skript/00-bilder/python3-standard-type-hierarchy.png){width=\"60%\" fig-alt=\"Dargestellt ist eine Kategorisierung der Standardtypen in Python. Die Kategorisierung ist nicht vollständig deckungsgleich zu den in der Dokumentation genannten Kategorien von Datentypen. Der Typ None für Nullwerte hat keine weitere Unterteilung. Die Kategorie Numbers unterteilt sich in Zahlenwerte (Ganzzahlen, boolsche Wahrheitswerte), reele Zahlen (floats) und komplexe Zahlen. Die Kategorie Sequences unterteilt sich in Unveränderliche (Strings, Tuple, Bytes) und Veränderliche (Listen, Byte Arrays). Die Kategorie Set Types unterteilt sich in Sets (Mengen) und Frozen Sets. Die Kategorie Mappings enthält Dictionaries (Wörterbücher). Die Kategorie Callable umfasst FUnktionen, Methoden und Klassen. Außerdem gibt es die Kategorie Module.\"}\n",
        "\n",
        "Python 3. The standard type hierarchy. von Максим Пе ist lizensiert unter [CC BY SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/deed.de) und abrufbar auf [wikimedia](https://commons.wikimedia.org/wiki/File:Python_3._The_standard_type_hierarchy.png). 2018\n",
        ":::\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Durch Module werden weitere Datentypen hinzugefügt. In der Datenanalyse häufig verwendete Datentypen sind:\n",
        "\n",
        "  - Zahlen: Ganzzahl, Fließkommazahlen\n",
        "\n",
        "  - Wahrheitswerte\n",
        "\n",
        "  - Zeichenketten\n",
        "\n",
        "  - Datums- und Uhrzeitangaben\n",
        "\n",
        "  - Kategorie<!-- Faktor in R--> (aus dem Modul [Pandas](https://pandas.pydata.org/docs/user_guide/categorical.html))\n",
        "\n",
        "Python enthält Funktionen, um den Datentyp eines Werts zu bestimmen und ggf. umzuwandeln. Einige dieser Funktionen werden exemplarisch vorgestellt.\n"
      ],
      "id": "dde19d9d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "a = 67 \n",
        "print(a, type(a))\n",
        "\n",
        "b = a + 1.8\n",
        "print(b, type(b), \"\\n\")\n",
        "\n",
        "print(f\"Umwandlung in Ganzzahlen mit int(): {( a := int(a) ), (b := int(b) )} - Beachten Sie das Abschneiden der Nachkommastelle.\\n\")\n",
        "\n",
        "print(f\"Umwandlung in ASCII-Zeichen mit chr(): {( a := chr(a) ), ( b := chr(b) )}\\n\")\n",
        "\n",
        "print(f\"Umwandlung in Zahlen mit ord(): {( a := ord(a) ), ( b := ord(b) )}\\n\")\n",
        "\n",
        "print(f\"Umwandlung in Fließkommazahlen mit float(): {( a := float(a) ), ( b := float(b) )}\\n\")\n",
        "\n",
        "print(f\"Umwandlung in Zeichen mit str(): {( a := str(a) ), ( b:= str(b) )}\\n\")\n",
        "\n",
        "print(f\"Umwandlung in Wahrheitswerte mit bool(): {bool(a), bool(b)}\")"
      ],
      "id": "292c5ade",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Datentyp bestimmt zum einen den zulässigen Wertebereich einer Variablen. Beispielsweise sind 0 und 13 zulässige Ganzzahlen, aber keine gültigen Kodierungen des Monats. Zum anderen definiert der Datentyp, welche Operationen mit den Werten zulässig sind und wie diese von Python ausgeführt werden. Dies betrifft Operatoren und Funktionen.\n",
        "\n",
        "::: {#nte-operation-nach-datentyp .callout-note}\n",
        "# Datentypabhängige Operationen und Funktionen\n"
      ],
      "id": "8a4aac34"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Der Operator + bewirkt die Addition von Zahlen\n",
        "print(1 + 13)\n",
        "\n",
        "# Der Operator + bewirkt auch das Verketten von strings\n",
        "print(str(1) + str(13))"
      ],
      "id": "c4333f0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Sortierfunktion arbeitet abhängig vom Datentyp."
      ],
      "id": "27d46c75"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Liste von Monatskürzeln erstellen\n",
        "dates = pd.Series([ '07.06.2000', '12.01.2000', '11.02.2000', '04.09.2000', '10.03.2000', '03.10.2000', '09.04.2000', '08.05.2000', '06.07.2000', '05.08.2000', '02.11.2000', '01.12.2000'])\n",
        "dates = pd.to_datetime(dates, format = '%d.%m.%Y');\n",
        "\n",
        "print(f\"Eine unsortierte Liste von Monatskürzeln:\\n{list(dates.dt.strftime(\"%b\"))}\")\n",
        "\n",
        "print(f\"\\nDie Liste alphabetisch sortiert:\\n{sorted(list(dates.dt.strftime(\"%b\")))}\")\n",
        "\n",
        "print(f\"\\nDie Liste als datetime-Objekt sortiert:\\n{list(dates.sort_values().dt.strftime(\"%b\"))}\")"
      ],
      "id": "d8f51245",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "Deshalb ist es beim Einlesen von Datensätzen wichtig, die korrekte Erkennung der Datentypen zu kontrollieren bzw. aktiv zu steuern. \n",
        "\n",
        "**TO DO: Tipps für Strategien der Fehlersuche und -bereinigung sammeln**\n",
        "**Strategien der Fehlersuche und -bereinigung: Korrektes Einlesen der Datentypen prüfen (bspw. nicht erkanntes Datetime führt nicht zu einer Fehlermeldung, sondern zum Einlesen als object) bzw. diese explizit spezifizieren, da Operationen auch mit falschen Datentypen fehlerfrei ausgeführt werden können. Listen haben in Python keinen Datentyp, man muss jedes Element prüfen!**\n",
        "**Strategien der Fehlersuche und -bereinigung: Einhaltung des zulässigen Wertebereichs überprüfen (mit .describe) --> guter Anfang, um Fehler im Datensatz zu finden (bspw. darf es keinen Monat 0 oder 13 geben).**\n",
        "\n",
        "### Fehlende Werte {#sec-missing}\n",
        "Ein besonderer Datentyp ist der zur Repräsentation fehlender Werte. In Python wird zwischen nicht existenten und nicht definierten Werten unterschieden.\n",
        "\n",
        "#### Nullwert None\n",
        "Der sogenannte Nullwert in Python ist `None`. `None` ist sowohl ein Objekt, als auch ein Datentyp der Klasse `NoneType`.\n"
      ],
      "id": "36c1a791"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test = None\n",
        "print(type(test))"
      ],
      "id": "6b0cac82",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`None` repräsentiert nicht existente Werte und Objekte. Leere (aber existente) Objekte gehören nicht zum Datentyp `None`.\n"
      ],
      "id": "505e7f5c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "leere_liste = []\n",
        "leere_liste == None"
      ],
      "id": "cbcace59",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`None` kann Funktionen als Argument übergeben oder von diesen als Rückgabewert ausgegeben werden. Operationen sind mit `None` jedoch nicht möglich. "
      ],
      "id": "370d63fc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Operationen mit None führen zu Fehlermeldungen\n",
        "def my_plusone(item):\n",
        "    try:\n",
        "      result = item + 1\n",
        "    except TypeError as error:\n",
        "       print(\"Der übergebene Wert führt zu der Fehlermeldung:\\n\", error)\n",
        "    else:\n",
        "      return result\n",
        "\n",
        "my_plusone(None)"
      ],
      "id": "4db88dd7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eine Ausnahme ist die Umwandlung in eine Zeichenkette."
      ],
      "id": "1523b4a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Eine Ausnahme ist die Umwandlung in strings\n",
        "a = None\n",
        "print(\"\\nprint(a) gibt den Nullwert zurück:\\n\", a, sep = \"\")\n",
        "\n",
        "print(\"\\nstr(a) gibt eine Zeichenkette zurück:\")\n",
        "str(a)"
      ],
      "id": "1d10d3e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Strategien der Fehlersuche und -bereinigung: Variablen mit Datentyp Zeichenkette (oder die als solche eingelesen werden) nach \"None\" durchsuchen.**\n",
        "\n",
        "#### NaN\n",
        "Um mit fehlenden Werten innerhalb eines Datensatzes arbeiten zu können, gibt es den Wert `NaN`, der zur Klasse der Fließkommazahlen gehört. `NaN` steht für Not a Number und repräsentiert undefinierte oder nicht darstellbare Werte. Beispielsweise berechnet die Methode `pd.diff()` die Differenz jedes Werts zu seinem Vorgänger. Da der erste Wert keinen Vorgänger hat, wird `NaN` erzeugt.\n"
      ],
      "id": "b5c030f8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_series = pd.Series([1, 2, 4, 8])\n",
        "my_series.diff()"
      ],
      "id": "09485248",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anders als `None` ist `NaN` kein Standardschlüsselwort in Python. Der Wert `NaN` wird erzeugt mit `float('nan')` oder `float('NaN')`, die Groß- und Kleinschreibung spielt keine Rolle. `NaN` hat also den Datentyp Fließkommazahl. Die Module math und NumPy bieten mit `math.nan` und `np.nan` ebenfalls Funktionen, um `NaN` zu erzeugen.\n"
      ],
      "id": "502a67fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test = float('NaN')\n",
        "print(type(test))"
      ],
      "id": "885aa3b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mit dem Wert 'NaN' können Operationen ausgeführt werden. Das Ergebnis ist immer `NaN`."
      ],
      "id": "ca839045"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(my_plusone(float('NaN')))"
      ],
      "id": "6537d7ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Viele **alle?!** Funktionen können mit `NaN` als Platzhalter für fehlende Werte umgehen."
      ],
      "id": "a8310261"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "daten_mit_nan = pd.Series([1, 2, float('NaN'), 4])\n",
        "print(daten_mit_nan + 1)\n",
        "print(\"\\nSumme des Datensates:\", daten_mit_nan.sum())"
      ],
      "id": "b9469c87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {#wrn-logicbasepython .callout-warning appearance=\"simple\" collapse=\"false\"}\n",
        "## Achtung Logik!\n",
        "\n",
        "Die logische Abfrage fehlender Werte unterscheidet sich für `None` und `NaN`. \n"
      ],
      "id": "88b41d91"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bool_values = [None, float('NaN')]\n",
        "\n",
        "for element in bool_values:\n",
        "  bool_value = bool(element)\n",
        "  print(\"Wahrheitswert von\", element, \"ist\", bool_value)"
      ],
      "id": "c43d54f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dies gilt auch für den logischen Identitätsabgleich."
      ],
      "id": "35e81cda"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for element in bool_values:\n",
        "  result = element == element\n",
        "  print(\"Identität von\", element, \"ist\", result)"
      ],
      "id": "fe858aa1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "### Fehlende Werte in der Praxis\n",
        "`None` und `NaN` sind pythonspezifische Repräsentationen für nicht existente oder nicht definierte Werte. In der Praxis werden fehlende Werte in Datensätzen auf unterschiedliche Weise gekennzeichnet. \n",
        "\n",
        "In Datensätzen übliche Werte sind:\n",
        "\n",
        "  - kein Eintrag, beispielsweise in kommaseparierten Dateien eine leere Zeichenkette `\"\"`\n",
        "\n",
        "  - definierte Zeichenfolge: `NA` (in der Programmiersprache R), `NULL` (in der Datenbanksprache SQL), `.` (in der Statistik-Software Stata)\n",
        "  \n",
        "  - (mehrere) manuell gewählte Zeichen oder Ziffern außerhalb des zulässigen Wertebereichs wie -1, -88, -99 (häufig bei Umfragedaten)\n",
        "\n",
        "Die Art der Kennzeichnung ist jeweils mit Vor- und Nachtteilen verbunden. Eine definierte Zeichenfolge für fehlende Werte hilft dabei, Lücken im Datensatz von Fehlern bei der Datenerfassung zu unterscheiden. Dazu ist eine definierte Zeichenfolge wie \"NA\" besser als eine leere Zeichenkette geeignet, führt aber auch leicht dazu, dass ein numerischer Datensatz als Zeichenkette erkannt wird. Manuell gewählte Werte erlauben es, bei der automatischen Auswertung eines Datensatzes abhängig von der Situation ein bestimmtes Verhalten für jede Variable festzulegen (z. B. Unterscheidung von nicht zutreffend, Aussage verweigert, weiß nicht, Interview abgebrochen keine Antwort).\n",
        "\n",
        "**Fehlersuche und -bereinigung: Man sollte sich über die im Dateiformat gängige Kennzeichnung fehlender Werte bewusstsein bzw. sich informieren. Hilfreich ist außerdem die Kenntnis disziplinärer Konventionen.**\n",
        "\n",
        "## Metadaten {#sec-metadaten}\n",
        "Metadaten sind beschreibende Informationen eines Datensatzes. Metadaten geben beispielsweise an:\n",
        "\n",
        "  - welche Datentypen ein Datensatz enthält,\n",
        "\n",
        "  - verwendete Kodierschemen, Skalen oder mimimal und maximal zulässige Werte,\n",
        "\n",
        "  - die Bedingungen, unter denen die Daten erhoben wurden,\n",
        "\n",
        "  - Herkunft der Daten,\n",
        "\n",
        "  - Beziehungen zwischen Variablen und Datensätzen,\n",
        "  \n",
        "  - urheberrechtliche Informationen und Lizenzhinweise.\n",
        "\n",
        "(vgl. [The HDF Group Help Desk](https://docs.hdfgroup.org/archive/support/HDF5/doc/Advanced/HDF5_Metadata/index.html))\n",
        "\n",
        "Spezialisierte Dateiformate wie netCDF oder HDF deklarieren Metadaten explizit in dafür vorgesehenen Feldern. Vielen Dateiformaten fehlt eine solche Funktion. Relevante Metadaten stehen deshalb häufig im Dateinamen (**Beispiel: SMARD-Daten**), in Spaltenbeschriftungen (**Beispiel: Zeitzone im österreichischen Strommarktdatensatz**), in zusätzlichen Tabellenblättern (**Beispiel besorgen**) oder in separaten Dokumenten (die nicht immer zur Verfügung stehen) **DWD-Daten von Jean-Luca**.\n",
        "\n",
        "**Fehlersuche und -vermeidung: Datensätze und, sofern vorhanden Begleitmaterialien, erst einmal angucken (Dateiname, ggf. Tabellenblätter und Spaltenbeschriftungen mit einem Tabellenkalkulationsprogramm kontrollieren.)**\n",
        "\n",
        "# Strukturierte Datensätze einlesen: die Module NumPy und Pandas\n",
        "Die Module NumPy und Pandas erlauben ein effizientes Arbeiten mit Datensätzen. Insbesondere das Lesen- und Schreiben von Dateien und die Verwaltung von Datentypen ist erheblich einfacher als mit der Python-Basis. Außerdem sind die vektorisierten Operationen vielfach schneller als Operationen mit Python. Das Modul Pandas basiert auf NumPy. In den folgenden Abschnitten werden beide Module behandelt.\n",
        "\n",
        "Eine kurze Übersicht der Vor- und Nachteile:\n",
        "\n",
        "  * NumPy: n-dimensionale Array-Struktur mit Unterstützung der am häufigsten verwendeten Datentypen sowie zahlreicher numerischer Formate für spezialisierte wissenschaftliche Berechnungen ([siehe Dokumentation](https://numpy.org/devdocs/reference/arrays.scalars.html)). Ein Array kann immer nur einen Datentyp haben und die Größe von Arrays ist unveränderlich. Dafür werden Operationen etwas schneller als in der DataFrame-Struktur von Pandas ausgeführt.  \n",
        "  **Querverweis auf w-NumPy**\n",
        "\n",
        "    - Spaltennamen sind mit einem strukturierten dtype möglich ([siehe Dokumentation](https://numpy.org/doc/stable/user/basics.io.genfromtxt.html#setting-the-names))\n",
        "\n",
        "  * Pandas: 2-dimensionale DataFrame-Struktur im long- und wide-Format. DataFrames können mehrere Datentypen enthalten und die Größe von DataFrames ist veränderlich. Unterstützung von alphanummerischen Spalten- und Indexbeschriftungen.  \n",
        "  **Querverweis auf w-Pandas**\n",
        "\n",
        "    - dreidimensionale DataFrames sind mit einem Multiindex möglich --> das widerspricht aber dem Konzept von Tidy Data\n",
        "\n",
        "Für beide Module haben sich diese Kürzel etabliert:\n"
      ],
      "id": "a0c7a9ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Deklarieren der Anzahl der Nachkommastellen\n",
        "pd.set_option(\"display.precision\", 2)"
      ],
      "id": "7c862cea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {#tip-pypandas .callout-tip collapse=\"false\"}\n",
        "## Arbeiten mit NumPy und Pandas\n",
        "Ob Sie mit NumPy oder mit Pandas arbeiten, hängt von dem vorliegenden Datensatz und persönlichen Präferenzen ab. \n",
        "\n",
        "Das Paket Pandas erlaubt es, Daten aus verschiedenen Quellen wie CSV-Dateien oder Excel-Tabellen und mit unterschiedlichen Datentypen in einen DataFrame zu laden. Anschließend können diese mit wenigen Befehlen untersucht und umstrukturiert werden. Komplexe Operationen wie das Umformen von Datensätzen, das Gruppieren und Aggregieren von Daten sowie das Filtern und Sortieren sind effizient möglich.\n",
        "\n",
        "Bis auf wenige Ausnahmen sind Pandas und NumPy zueinander kompatibel. Es spricht nichts dagegen, Ihre Daten mit Pandas vorzubereiten und anschließend mit NumPy auszuwerten.\n",
        "\n",
        ":::\n",
        "\n",
        "## Datentypen\n",
        "NumPy unterstützt folgende Datentypen:\n",
        "\n",
        "|      Datentyp NumPy-Array  |      Datentyp in Python |\n",
        "|---|---|\n",
        "|     int_    |     int    |\n",
        "|     double    |     float    |\n",
        "|     cdouble    |     complex    |\n",
        "|     bytes_    |     bytes    |\n",
        "|     str_    |     str    |\n",
        "|     bool_    |     bool    |\n",
        "|     datetime64    |     datetime.datetime    |\n",
        "|     timedelta64    |     datetime.timedelta    |\n",
        "\n",
        "[Dokumentation NumPy](https://numpy.org/devdocs/reference/arrays.scalars.html)\n",
        "\n",
        "In den meisten Fällen verwendet das Modul Pandas die NumPy-Datentypen. Pandas führt aber auch einige zusätzliche Datentypen ein. Eine vollständige Liste finden Sie in der [Pandas Dokumentation](https://pandas.pydata.org/docs/reference/arrays.html). Die wichtigsten zusätzlichen Datentypen sind:\n",
        "\n",
        "  - [Kategorie](https://pandas.pydata.org/docs/user_guide/categorical.html) `dtype = category`\n",
        "\n",
        "  - [Zeitzonenbewusstes Datumsformat](https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html#pandas.Timestamp) `DatetimeTZDtype` **wie heißt der Datentyp?!**\n",
        "\n",
        "## Dateien lesen und schreiben\n",
        "In den Werkzeugbaustein NumPy und Pandas haben Sie die Funktionen zum Lesen und Schreiben von Dateien kennengelernt.\n",
        "\n",
        "::: {.panel-tabset}\n",
        "## NumPy\n",
        "In NumPy können Dateien mit der Funktion `np.loadtxt()` gelesen und mit der Funktion `np.savetxt()` geschrieben werden. \n",
        "\n",
        "  - `np.loadtxt(fname = data.txt, delimiter = \";\", skiprows= #Reihen)`  \n",
        "\n",
        "  - `np.savetxt(fname = dateipfad, X = daten, header = kommentar, fmt='%5.2f')`\n",
        "\n",
        "## Pandas\n",
        "In Pandas werden Dateien mit einer Reihe spezialisierter Funktionen gelesen und geschrieben, die einem einheitlichen Schema folgen. Funktionen zum Lesen von Dateien werden in der Form `pd.read_csv` und Funktionen zum Schreiben in der Form `pd.to_csv` aufgerufen.\n",
        "\n",
        ":::: {.border}\n",
        "| Format Type | Data Description | Reader | Writer |\n",
        "|:---:|:---:|:---:|:---:|\n",
        "| text | CSV | read_csv | to_csv |\n",
        "| text | Fixed-Width Text File | read_fwf | NA |\n",
        "| text | JSON | read_json | to_json |\n",
        "| text | HTML | read_html | to_html |\n",
        "| text | LaTeX | Styler.to_latex | NA |\n",
        "| text | XML | read_xml | to_xml |\n",
        "| text | Local clipboard | read_clipboard | to_clipboard |\n",
        "| binary | MS Excel | read_excel | to_excel |\n",
        "| binary | OpenDocument | read_excel | NA |\n",
        "| binary | HDF5 Format | read_hdf | to_hdf |\n",
        "| binary | Feather Format | read_feather | to_feather |\n",
        "| binary | Parquet Format | read_parquet | to_parquet |\n",
        "| binary | ORC Format | read_orc | to_orc |\n",
        "| binary | Stata | read_stata | to_stata |\n",
        "| binary | SAS | read_sas | NA |\n",
        "| binary | SPSS | read_spss | NA |\n",
        "| binary | Python Pickle Format | read_pickle | to_pickle |\n",
        "| SQL | SQL | read_sql | to_sql |\n",
        "\n",
        "([Pandas Dokumentation](https://pandas.pydata.org/docs/user_guide/io.html))\n",
        "::::\n",
        "::: \n",
        "\n",
        "## Datentypen erkennen und festlegen\n",
        "Der Datentyp bestimmt, wie bereits ausgeführt, den zulässigen Wertebereich einer Variablen, zulässige Operationen und die Ausführung von Operatoren und Funktionen in Python. Die Module NumPy und Pandas bieten eine Reihe von Funktionen, um den Datentyp von Variablen zu kontrollieren und festzulegen. \n",
        "\n",
        "**ergänzen: Datumsformat Hinweis auf Zeitreihen [@sec-zeitreihen]**\n",
        "\n",
        "### NumPy\n",
        "Mit NumPy kann der Datentyp eines Arrays beim Einlesen einer Datei mit dem Argument `dtype` festgelegt werden `np.loadtxt(fname = data.txt, dtype = 'float'`. Das Argument `dtype` akzeptiert die Angabe eines Datentyps sowie Schlüsselwörter oder Kürzel. Weiter Informationen erhalten Sie in der [NumPy Dokumentation](https://numpy.org/doc/stable/reference/arrays.dtypes.html).\n",
        "\n",
        "| Datentyp | Schlüsselwort | Kürzel | dtype |\n",
        "|---|---|---|---|\n",
        "| Fließkommazahl | float | f8 | float64 |\n",
        "| Ganzzahl | int | i | int32 |\n",
        "| Wahrheitswert | bool | ? | bool |\n",
        "| Datum | datetime64 | M | datetime64 |\n",
        "| Zeichenkette | str | U | U + Ziffer zur Angabe der benötigten Bytes |\n",
        "\n",
        "Der Datentyp eines Arrays kann mit der Methode `np.dtype` bestimmt werden. Der Datentyp eines Objekts kann mit der Methode `np.array = np.array.astype()` geändert werden.\n",
        "\n",
        "\n",
        "Folgende Datei ist Ihnen aus dem w-NumPy bekannt.\n"
      ],
      "id": "a26b3b22"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = 'skript/01-daten/TC01.csv'\n",
        "daten = np.loadtxt(dateipfad)"
      ],
      "id": "12906aaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Prüfen Sie den dtype der Datei und legen Sie eine Kopie des Objekts mit Dateityp Ganzzahl an. Wie kann überprüft werden, ob bei der Umwandlung in Ganzzahlen Nachkommastellen abgeschnitten wurden?**\n",
        "\n",
        "::: {#tip-numpydatentyp .callout-tip collapse=\"true\"}\n",
        "## Musterlösung Datentypumwandlung\n"
      ],
      "id": "9868100a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ausgabe des Datentyps\n",
        "print(daten.dtype)\n",
        "\n",
        "# Umwandlung in Ganzzahl\n",
        "daten_int = daten.astype('int')\n",
        "\n",
        "# Prüfen auf Datenverlust\n",
        "prüfsumme = daten - daten_int\n",
        "print(f\"Differenz daten - daten_int: {prüfsumme.sum()}\")"
      ],
      "id": "f4744bb8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "### Pandas\n",
        "Das Modul Pandas ist auf den Umgang mit unterschiedlichen Datentypen spezialisiert. Den Funktionen zum Einlesen von Daten kann mit dem Argument `dtype` der Datentyp übergeben werden. Für mehrere Spalten ist dies in Form eines Dictionaries in der Form `{'Spaltenname': 'dtype'}` möglich.  \n",
        "Das Atrribut zur Ausgabe des Datentyps heißt passenderweise `pd.DataFrame.dtypes` (angefügtes s beachten). Der Datentyp eines Pandas-Datenobjekts kann analog zu NumPy mit 'pd.Series = pd.Series.astype()' geändert werden.\n",
        "\n",
        "#### Vitamin C bei Meerschweinchen\n",
        "In einer Gruppe von 60 Meerschweinchen (**1. Spalte ohne Beschriftung**) wurde die Länge der zahnbildenden Zellen (Odontoblasten) in Micron gemessen (**len**). Den Tieren wurde zuvor Vitamin C in Form von Ascorbinsäure (VC) oder Orangensaft (VC) verabreicht (**supp**). Die Meerschweinchen erhielten Dosen von 0.5, 1 oder 2 Milligramm Vitamin C pro Tag  (**dose**). Die Messdaten sind in der Datei ToothGrowth.csv gespeichert (Crampton 1947.)\n",
        "\n",
        "::: {.border}\n",
        "Crampton, E. W. 1947. „THE GROWTH OF THE ODONTOBLASTS OF THE INCISOR TOOTH AS A CRITERION OF THE VITAMIN C INTAKE OF THE GUINEA PIG“. The Journal of Nutrition 33 (5): 491–504. <https://doi.org/10.1093/jn/33.5.491> \n",
        ":::\n",
        "\n",
        "&nbsp;\n",
        "\n",
        " **Lesen Sie die Datei wie folgt ein:**\n",
        "\n",
        "  - Die Spaltenbeschriftung der 1. Spalte soll mit der Beschriftung 'ID' ersetzt werden (ohne Anführungszeichen).\n",
        "  \n",
        "  - Die Spalten len und dose sollen mit geeigneten numerischen Datentypen, die Spalte supp als Kategorie eingelesen werden.\n",
        "\n",
        "::: {#tip-meerschweinchen .callout-tip collapse=\"true\"}\n",
        "## Musterlösung Meerschweinchen"
      ],
      "id": "24785052"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = \"skript/01-daten/ToothGrowth.csv\"\n",
        "meerschweinchen = pd.read_csv(filepath_or_buffer = dateipfad, sep = ',', header = 0, \\\n",
        "  names = ['ID', 'len', 'supp', 'dose'], dtype = {'ID': 'int', 'len': 'float', 'dose': 'float', 'supp': 'category'})\n",
        "\n",
        "# Ausgabe jedes sechsten Werts\n",
        "meerschweinchen.iloc[meerschweinchen.index % 6 == 0]"
      ],
      "id": "8279ef18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(meerschweinchen.dtypes)"
      ],
      "id": "cd4e88f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "#### Nützliche Funktionen\n",
        "Pandas bietet einige praktische Funktionen, um den Aufbau eines Datensatzes zu beschreiben.\n",
        "\n",
        "Das Attribut `.columns` gibt die Spaltenbeschriftungen als Liste zurück. Ebenfalls ist darüber ein Schreibzugriff möglich."
      ],
      "id": "471345fc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(meerschweinchen.columns)\n",
        "meerschweinchen.columns = ['ID', 'Länge', 'Verabreichung', 'Dosis']"
      ],
      "id": "6d1a6c92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Methode `pd.DataFrame.describe()` erzeugt eine beschreibende Statistik für einen DataFrame. Standardmäßig werden alle numerischen Spalten berücksichtigt. Mit dem Argument `include` können die zu berücksichtigenden Spalten vorgegeben werden. 'all' berücksichtigt alle Spalten, was nicht unbedingt sinnvoll ist. Alternativ kann eine Liste zu berücksichtigender Datentypen übergeben werden. Das Argument `exclude` schließt auf die gleiche Weise Datentypen von der Ausgabe aus.\n"
      ],
      "id": "81783709"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(meerschweinchen.describe(), \"\\n\")\n",
        "\n",
        "print(meerschweinchen.describe(include = 'all'), \"\\n\")\n",
        "\n",
        "print(meerschweinchen.describe(include = ['float']), \"\\n\")"
      ],
      "id": "13cdac90",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Methode `pd.DataFrame.count()` zählt alle vorhandenen Werte in jeder Spalte (oder in jeder Zeile mit `pd.DataFrame.count(axis = 'columns')`)."
      ],
      "id": "42b1dc5c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "meerschweinchen.count(axis = 'rows') # der Standardwert von axis ist 'rows'"
      ],
      "id": "44dd5c4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Methode `pd.DataFrame.info()` erzeugt eine Beschreibung des Datensatzes. "
      ],
      "id": "e926c283"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "meerschweinchen.info()"
      ],
      "id": "70845dba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Methode `pd.unique()` listet alle einzigartigen Werte auf."
      ],
      "id": "ba245439"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "meerschweinchen['Dosis'].unique()"
      ],
      "id": "b1a39f05",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {#tip-pandasinfo .callout-tip collapse=\"false\"}\n",
        "## Nützliche Funktionen\n",
        "Tipp: Pandas bietet einige praktische Funktionen, um eine eingelesene Datei zu kontrollieren. Machen Sie sich die Verwendung von `pd.dtypes` oder `pd.DataFrame.info()` zur Angewohnheit. \n",
        ":::\n",
        "\n",
        "### Aufgabe Datentypen\n",
        "Das britische Energieministerium veröffentlicht Daten zu den Strompreisen in den Mitgliedsändern der Internationalen Energieagentur. **Lesen Sie Tabellenblatt \"5.3.1 (excl. taxes)\" aus der Excel-Datei 'skript/01-daten/table_531.xlsx' mit Pandas ein. Stellen Sie sicher, dass alle Spalten mit einem numerischen Datentyp eingelesen werden.**\n",
        "\n",
        "::: {.border}\n",
        "Department for Energy Security & Net Zero. 2024. Energy Prices International Comparisons. Industrial electricity prices in the IEA. <https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/670121/table_531.xls>\n",
        ":::\n",
        "\n",
        "::: {#tip-taxes .callout-tip collapse=\"true\"}\n",
        "## Musterlösung taxes\n",
        "\n",
        "Überspringen der führenden Zeilen mit dem Argument `header = 8`. Auswahl des Tabellenblatts mit `sheet_name = \"5.3.1 (excl. taxes)\"` und Kontrolle der erkannten Datentypen mit `taxes.dtypes` "
      ],
      "id": "08727255"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = 'skript/01-daten/table_531.xlsx'\n",
        "\n",
        "taxes = pd.read_excel(io = dateipfad, sheet_name = \"5.3.1 (excl. taxes)\", \\\n",
        "  header = 8)\n",
        "\n",
        "taxes.dtypes"
      ],
      "id": "cc2da039",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Werte in Spalte 'Republic of Türkiye' mit `pd.unique()` ansehen."
      ],
      "id": "5d4b2804"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "taxes['Republic of Türkiye'].unique()"
      ],
      "id": "399d5328",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Zeichenkette '..' entfernen und Datentyp mit Methode `pd.astype('float64')` ändern.\n",
        "\n",
        "  - Variante 1: als fehlenden Wert beim Einlesen deklarieren. \n",
        "  \n",
        "  - Variante 2: Nach dem Einlesen Indexposition bestimmen und Wert ersetzen.\n",
        "  \n",
        "    - Das verkettete Slicing `df[\"col\"][row_indexer] = value` wird mit der Pandas Version 3.0 nicht mehr unterstützt und gibt deshalb eine Fehlermeldung aus.\n",
        "    \n",
        "    - Künftig ist folgende Synthax zu verwenden: `df.loc[row_indexer, \"col\"] = value` \n"
      ],
      "id": "54d71320"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Variante 1: '..' als fehlenden Wert deklarieren\n",
        "# taxes = pd.read_excel(io = dateipfad, sheet_name = \"5.3.1 (excl. taxes)\", \\\n",
        "#   header = 8, na_values = ['..'])\n",
        "\n",
        "# Variante 2: Index des Werts bestimmen und mit np.NaN überschreiben\n",
        "## verkettetes Slicing funktioniert, gibt aber eine Fehlermeldung aus\n",
        "## Slicing mit df.loc[row_indexer, \"col\"] \n",
        "# indexposition = taxes['Republic of Türkiye'] == '..'\n",
        "\n",
        "# taxes.loc[ indexposition, 'Republic of Türkiye' ] = np.NaN\n",
        "# taxes['Republic of Türkiye'] = taxes['Republic of Türkiye'].astype('float64')\n",
        "\n",
        "# Variante 3: np.argwhere()\n",
        "indexposition = np.argwhere(taxes['Republic of Türkiye'] == '..')\n",
        "\n",
        "taxes.loc[ indexposition, 'Republic of Türkiye' ] = np.NaN\n",
        "taxes['Republic of Türkiye'] = taxes['Republic of Türkiye'].astype('float64')\n",
        "\n",
        "taxes.dtypes"
      ],
      "id": "34933a77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Umgang mit fehlenden Werten\n",
        "Eine unerwartet als string oder object eingelesene Spalte weist häufig auf fehlende Werte hin, die durch Sonderzeichen gekennzeichnet sind. Die Module NumPy und Pandas bieten funktionen, um fehlende Werte bereits beim Einlesen zu erkennen und umzuwandeln.\n",
        "\n",
        "### NumPy\n",
        "Die NumPy-Funktion `np.loadtxt()` wird verwendet, um vollständige Datensätze einzulesen. Fehlende Werte im Datensatz können problematisch sein, da diese entweder zu Fehlermeldungen bezüglich des Datentyps führen oder übersprungen werden, sodass das NumPy-Array kürzer als der eingelesene Datensatz ist. Da NumPy-Arrays immer nur einen Datentyp und eine feste Länge haben, kann das bei der Durchführung von Operationen mit mehreren Arrays zu Fehlern führen.\n",
        "\n",
        "Folgende Datei ist Ihnen aus dem w-NumPy bekannt."
      ],
      "id": "79909f38"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = 'skript/01-daten/TC01.csv'\n",
        "daten_ohne_fehlende_werte = np.loadtxt(dateipfad)\n",
        "\n",
        "print(\"Daten:\", daten_ohne_fehlende_werte)\n",
        "print(\"Struktur:\", daten_ohne_fehlende_werte.shape, \"dtype:\", daten_ohne_fehlende_werte.dtype)"
      ],
      "id": "1180094c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Angenommen, Sie haben eine zweite Messung durchgeführt und möchten die Differenz beider Datensätze berechnen. In der zweiten Messung haben Sensorfehler zu fehlenden Werten geführt, die mit '--' markiert sind. Die Funktion `np.loadtxt()` kann jedoch mit fehlenden Werten nicht umgehen und gibt eine Fehlermeldung zurück. \n"
      ],
      "id": "74ef7218"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = 'skript/01-daten/TC01_double_hyphen.csv'\n",
        "\n",
        "try:\n",
        "  daten_double_hypen = np.loadtxt(dateipfad)\n",
        "except ValueError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(\"Daten mit fehlenden Werten '--':\", daten_double_hypen, \"dtype:\", daten_double_hypen.dtype) \n"
      ],
      "id": "5a62b60f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Die Funktion np.genfromtxt()\n",
        "Um Datensätze mit fehlenden Werten einzulesen, wird die Funktion `np.genfromtxt(fname, delimiter = None, missing_values = None, filling_values = None)` verwendet. Dieses durchläuft den Datensatz `fname` in zwei Schleifen, weshalb die Funktion langsamer als `np.loadtxt()` ist. Die erste Schleife teilt den Datensatz zeilenweise am optional übergebenen Trennzeichen `delimiter` in eine Zeichenkette auf. Die zweite Schleife konvertiert jede Zeichenkette in den passenden Datentyp. Mit den optionalen Argumenten `missing_values` und `filling_values` können der Funktion Zeichenfolgen übergeben werden, mit der fehlende Werte markiert sind bzw. ersetzt werden sollen. ([NumPy Dokumentation](https://numpy.org/doc/stable/user/basics.io.genfromtxt.html))\n"
      ],
      "id": "8b0179c3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = 'skript/01-daten/TC01_double_hyphen.csv'\n",
        "daten_double_hypen = np.genfromtxt(dateipfad, missing_values = '--', filling_values = np.nan)\n",
        "\n",
        "print(\"\\nDaten mit fehlenden Werten '--':\", daten_double_hypen)\n",
        "print(\"Struktur:\", daten_double_hypen.shape, \"dtype:\", daten_ohne_fehlende_werte.dtype)"
      ],
      "id": "1f68e82c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch die Umwandlung fehlender Werte in `NaN`, sind Operationen mit gleichlangen NumPy-Arrays möglich.\n"
      ],
      "id": "f7d7f53d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "daten_differenz = daten_ohne_fehlende_werte - daten_double_hypen\n",
        "print(daten_differenz)"
      ],
      "id": "e2a6edfb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Funktion `np.genfromtxt()` kann beliebige Zeichenketten als fehlenden Wert verarbeiten. Lediglich leere Zellen können problematisch sein, da deren Inhalt `'\\n'` als Zeilentrenner verarbeitet wird.\n",
        "\n",
        "::: {#nte-npgenfromtxt .callout-note collapse=\"true\"}\n",
        "## Leere Zellen mit np.genfromtxt()\n",
        "\n",
        "Enthält eine Datei leere Zellen, können diese nicht eingelesen werden, da diese automatisch übersprungen werden."
      ],
      "id": "1bd86853"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Datei ohne Markierung fehlender Werte\n",
        "dateipfad = 'skript/01-daten/TC01_empty_lines.csv'\n",
        "daten_empty_lines = np.genfromtxt(dateipfad, missing_values = '', filling_values = np.nan) \n",
        "\n",
        "print(\"\\nDaten mit fehlenden Werten '':\", daten_empty_lines)\n",
        "print(\"Struktur:\", daten_empty_lines.shape, \"dtype:\", daten_empty_lines.dtype)"
      ],
      "id": "5db1ba01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Das Array ist zwei Elemente kürzer. Die Subtraktion von einem längeren NumPy-Array scheitert mit einer Fehlemeldung.\n"
      ],
      "id": "ca617b38"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "  result = daten_ohne_fehlende_werte - daten_empty_lines\n",
        "except ValueError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(result)"
      ],
      "id": "17b56930",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In diesem Fall muss auf die Stringbearbeitung aus der Python-Basis zurückgegriffen werden. Die bearbeitete Liste kann wie gewohnt mit `np.genfromtxt()` eingelesen werden.\n"
      ],
      "id": "8c084fd1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Einlesen über Datenobjekt\n",
        "datenobjekt_empty_lines = open(dateipfad, 'r', encoding = 'utf-8')\n",
        "daten_empty_lines = datenobjekt_empty_lines.readlines()\n",
        "datenobjekt_empty_lines.close()\n",
        "\n",
        "print(\"Das ausgelesene Datenobjekt (Ausschnitt):\\n\", daten_empty_lines[0:10])\n",
        "\n",
        "# Stringbearbeitung mit replace('\\n', '')\n",
        "for i in range(len(daten_empty_lines)):\n",
        "\n",
        "  if daten_empty_lines[i] == '\\n':\n",
        "    daten_empty_lines[i] = 'platzhalter'\n",
        "  else:\n",
        "    daten_empty_lines[i] = daten_empty_lines[i].replace('\\n', '')\n",
        "\n",
        "print(\"\\nNach der Stringbearbeitung (Ausschnitt):\\n\", daten_empty_lines[0:10])\n",
        "\n",
        "# Einlesen mit np.genfromtxt\n",
        "daten_empty_lines = np.genfromtxt(daten_empty_lines, missing_values = 'platzhalter', filling_values = np.nan)\n",
        "print(\"\\nDaten mit fehlenden Werten '':\", daten_empty_lines)\n",
        "print(\"Struktur:\", daten_empty_lines.shape, \"dtype:\", daten_empty_lines.dtype)"
      ],
      "id": "049ec84c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "Besonders bei Dateien mit mehreren Spalten führen leere Zellen schnell zu Fehlern. Hier ist es erforderlich, den Zeichentrenner mit dem Argument `delimiter` zu spezifizieren. Aus der Dokumentation:  \n",
        "\"When spaces are used as delimiters, or when no delimiter has been given as input, there should not be any missing data between two fields.\" ([NumPy Dokumentation](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html))\n",
        "\n",
        "::: {#nte-npgenfromtxt .callout-note collapse=\"true\"}\n",
        "## Leere Zellen in mehreren Spalten mit np.genfromtxt()\n",
        "Ohne Spezifikation des Arguments `delimiter` wird nur eine Spalte eingelesen, die ausschließlich `np.nan` enthält."
      ],
      "id": "bfcebb5f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ohne Spezifikation von delimiter\n",
        "dateipfad = 'skript/01-daten/TC01_missing_values_multi_column.csv'\n",
        "daten_empty_lines2 = np.genfromtxt(dateipfad, missing_values = '', filling_values = np.nan, ndmin = 2)\n",
        "\n",
        "print(\"Struktur:\", daten_empty_lines2.shape, \"dtype:\", daten_empty_lines2.dtype)\n",
        "print(\"Die ersten drei Zeilen:\\n\", daten_empty_lines2[0:3])"
      ],
      "id": "7dde21e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wird das Argument `delimiter = ','` übergeben, wird die Datei korrekt eingelesen."
      ],
      "id": "5893841e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# mit Spezifikation von delimiter\n",
        "daten_empty_lines2 = np.genfromtxt(dateipfad, delimiter = ',', missing_values = '', filling_values = np.nan, ndmin = 2)\n",
        "\n",
        "print(\"Struktur:\", daten_empty_lines2.shape, \"dtype:\", daten_empty_lines2.dtype)\n",
        "print(\"\\nDaten mit fehlenden Werten '':\\n\", daten_empty_lines2)"
      ],
      "id": "b23e7ed3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "#### Fehlende Werte in NumPy erzeugen, prüfen, finden, ersetzen, löschen\n",
        "Das Modul NumPy bietet Funktionen, um mit fehlenden Werten zu arbeiten.\n",
        "\n",
        "  - `np.nan` erzeugt einen fehlenden Wert.\n",
        "\n",
        "  - `np.isnan()` prüft auf einen fehlenden Wert und gibt einen Wahrheitswert bzw. ein NumPy-Array mit dtype bool zurück.\n",
        "\n",
        "  - `np.nonzero(np.isnan(array))` gibt ein Tuple zurück, das ein Array mit den Indexpositionen der Elemente mit dem Wert 'NaN' enthält. Auf das Array kann mit `np.nonzero(np.isnan(array))[0]` zugegriffen werden. Je nach Situation kann die Umwandlung in eine Liste nützlich sein `np.nonzero(np.isnan(array))[0].tolist()`.  \n",
        "  **Geht das nicht einfacher?! `np.argwhere(np.isnan(array))` ... aber in der Doku steht: The output of argwhere is not suitable for indexing arrays. For this purpose use nonzero(a) instead. **\n",
        "\n",
        "  - `nan_to_num(x = array, nan = 0.0)` ersetzt im Array x `NaN` durch den Wert 0.0 oder durch den im Argument `nan` übergebenen Wert. (Hinweis: `nan_to_num()` ersetzt standardmäßig auch np.inf durch große positive sowie -np.inf durch große negative Zahlen.)\n",
        "\n",
        "  - `np.delete(arr = array, obj)` gibt ein neues (kürzeres) Array ohne die im Parameter obj spezifizierten Array-Bereiche zurück. Alle Elemente mit dem Wert `NaN` werden so gelöscht: `np.delete(array, obj = np.nonzero(np.isnan(array)))`  \n",
        "\n",
        "**Kleine Aufgabe zwischendurch: Die Funktion `np.argwhere(np.array == np.nan)` soll die Indizes der Elemente zurückgeben, die den Wert np.nan haben. Warum ist die Liste immer leer?**  \n",
        "\n",
        "NumPy wandelt `None` nicht automatisch in `NaN` um. NumPy kann den Datentyp des Objekts deshalb nicht bestimmen und gibt `dtype=object` aus:\n"
      ],
      "id": "f5dba762"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_array_with_none = np.array([1, 2, None, 4])\n",
        "print(np_array_with_none, np_array_with_none.dtype)"
      ],
      "id": "84ef17ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Aufgabe: Wie kann `None` durch `np.nan` ersetzt werden?**\n",
        "\n",
        "::: {#tip-numpynone .callout-tip collapse=\"true\"}\n",
        "## Lösung\n",
        "Eine logische Abfrage von `None` ist möglich. Auf diese Weise kann ein logisches Array erzeugt werden, das zur Auswahl der Indexpositionen verwendet wird, deren Werte ersetzt werden sollen."
      ],
      "id": "64177cbd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_array_with_none = np.array([1, 2, None, 4])\n",
        "print(np_array_with_none)\n",
        "\n",
        "np_array_with_nan = np_array_with_none.copy()\n",
        "\n",
        "print(f\"\\nArray mit logischer Abfrage von None:\\n{np_array_with_none == None}\")\n",
        "np_array_with_nan[np_array_with_none == None] = np.nan\n",
        "print(f\"\\nArray mit None ersetzt durch NaN:\\n{np_array_with_nan, np_array_with_nan.dtype}\")"
      ],
      "id": "ef92d5e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: \n",
        "\n",
        "&nbsp;\n",
        "\n",
        "#### Operationen mit fehlenden Werten\n",
        "Operationen mit `NaN` ergeben immer `NaN`. Deshalb gibt es in NumPy viele Funktionen, die `NaN` automatisch ignorieren bzw. durch einen geeigneten Wert ersetzen. Diese sind bereits am Funktionsnamen erkennbar. Beispielsweise liefern `np.nansum()` und `np.nancumsum()` die Summe bzw. die kumulierte Summe eines Arrays. In der kumulierten Summe werden `NaN` durch das laufende Ergebnis ersetzt. Eine vollständige Liste der NumPy-Funktionen finden Sie in der [Dokumentation](https://numpy.org/doc/stable/reference/routines.html).\n"
      ],
      "id": "7764d3b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Array mit NaN:\\n{np_array_with_nan}\\n\")\n",
        "\n",
        "print(f\"Summe des Arrays:\\n{np.sum(np_array_with_nan)}\\n\")\n",
        "\n",
        "print(f\"NaN-Summe des Arrays:\\n{np.nansum(np_array_with_nan)}\\n\")\n",
        "\n",
        "print(f\"kumulierte Summe des Arrays:\\n{np.cumsum(np_array_with_nan)}\\n\")\n",
        "\n",
        "print(f\"kumulierte NaN-Summe des Arrays:\\n{np.nancumsum(np_array_with_nan)}\\n\")"
      ],
      "id": "069a7476",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pandas\n",
        "Die Pandas-Funktionen zum Lesen von Dateien können mit fehlenden Werten umgehen. Standardmäßig werden folgende Werte als fehlende Werte erkannt:  \n",
        "`['-1.#IND', '1.#QNAN', '1.#IND', '-1.#QNAN', '#N/A N/A', '#N/A', 'N/A', 'n/a', 'NA', '<NA>', '#NA', 'NULL', 'null', 'NaN', '-NaN', 'nan', '-nan', 'None', '']`\n",
        "\n",
        "Weitere Werte können mit dem Argument `na_values = []` als fehlende Werte definiert werden. Mit dem Argument `keep_default_na = False` kann festgelegt werden, dass ausschließlich die in `na_values = []` übergebenen Werte als fehlende Werte interpretiert werden sollen. Standardmäßig werden mit dem Argument `na_filter = True` auch leere Zellen als NA eingelesen. Vollständig leere Zeilen werden jedoch standardmäßig übersprungen. Dies kann mit dem Argument `skip_blank_lines = False` geändert werden. ([Pandas Dokumentation](https://pandas.pydata.org/docs/user_guide/io.html#io-navaluesconst))  \n",
        "\n",
        "Fehlende Werte können mit dem Argument `na_values = []` spezifiziert werden."
      ],
      "id": "3d370cbe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = 'skript/01-daten/TC01_double_hyphen.csv'\n",
        "\n",
        "try:\n",
        "  daten_double_hypen = pd.read_csv(dateipfad, na_values = ['--'])\n",
        "except ValueError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(\"Daten mit fehlenden Werten '--':\\n\", daten_double_hypen, daten_double_hypen.shape) "
      ],
      "id": "5d6888bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**merken: das Objekt wird als object eingelesen, dass wird gleich überprüft... ich habe Datentypen nach vorne gelegt.**\n",
        "\n",
        "Mit dem Argument `skip_blank_lines = False` werden leere Zeilen ebenfalls eingelesen. "
      ],
      "id": "631a9609"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = 'skript/01-daten/TC01_empty_lines.csv'\n",
        "\n",
        "try:\n",
        "  daten_empty_lines = pd.read_csv(dateipfad, skip_blank_lines = False)\n",
        "except ValueError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(\"Daten mit fehlenden Werten '':\\n\", daten_empty_lines, daten_empty_lines.shape) "
      ],
      "id": "8c038153",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pandas verwendet abhängig vom Datentyp verschiedene Werte zur Kennzeichnung fehlender Werte.\n",
        "\n",
        "  - `numpy.nan` für NumPy-Datentypen. Hierbei wird der Datentyp automatisch in `np.float64` oder `object` konvertiert.\n",
        "\n",
        "  - `NA` für Zeichenketten und Ganzzahlen. Der Datentyp bleibt erhalten.\n",
        "\n",
        "Einlesen der Datei TC01_empty_lines.csv als string:"
      ],
      "id": "5ee8df7e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = 'skript/01-daten/TC01_empty_lines.csv'\n",
        "\n",
        "try:\n",
        "  daten_empty_lines = pd.read_csv(dateipfad, skip_blank_lines = False, dtype = 'string')\n",
        "except ValueError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(\"Daten mit fehlenden Werten '':\\n\", daten_empty_lines, daten_empty_lines.shape) "
      ],
      "id": "45268c6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`NA` kann zwar auch als fehlender Wert für Gleitkommazahlen und andere NumPy Datentypen verwendet werden. Allerdings wird dafür ein erweiterter Pandas Dateityp benötigt (siehe das folgende Beispiel).\n",
        "\n",
        "::: {#nte-pdNA .callout-note collapse=\"true\"}\n",
        "## pd.Series mit np.nan und pd.NA\n",
        "Eine pd.Series mit `np.nan` wird automatisch in `dtype: float64` umgewandelt: "
      ],
      "id": "d4bbfcae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "  test = pd.Series([1, 2, np.nan])\n",
        "except TypeError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(test) "
      ],
      "id": "ace30b89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eine pd.Series mit `pd.NA` wird als `dtype: object` eingelesen: "
      ],
      "id": "570695ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "  test = pd.Series([1, 2, pd.NA])\n",
        "except TypeError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(test) "
      ],
      "id": "6b04faac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der `dtype` kann für eine Series mit `pd.NA` festgelegt werden: "
      ],
      "id": "b8359045"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "  test = pd.Series([1, 2, pd.NA], dtype = 'Int32')\n",
        "except TypeError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(test) "
      ],
      "id": "1f5cbc79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Abhängig vom Datentyp kommt es auf den korrekten `dtype` (NumPy oder Pandas) an, erkennbar an der Groß- und Kleinschreibung. `pd.NA` mit Numpy-Fließkommazahl: "
      ],
      "id": "7454bbbb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "  test = pd.Series([1, 2, pd.NA], dtype = 'float64')\n",
        "except TypeError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(test) "
      ],
      "id": "79de8919",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`pd.NA` mit Pandas-Fließkommazahl:"
      ],
      "id": "d57a2477"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "  test = pd.Series([1, 2, pd.NA], dtype = 'Float64')\n",
        "except TypeError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(test) "
      ],
      "id": "468549cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`np.nan` mit Numpy-Fließkommazahl:"
      ],
      "id": "ad2286c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "  test = pd.Series([1, 2, np.nan], dtype = 'float64')\n",
        "except TypeError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(test) "
      ],
      "id": "7b297fa4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`np.nan` mit Pandas-Fließkommazahl:"
      ],
      "id": "d519eeb3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "  test = pd.Series([1, 2, np.nan], dtype = 'Float64')\n",
        "except TypeError as error:\n",
        "  print(\"Die Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(test) "
      ],
      "id": "6055469f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "**Fehlersuche und -bereinigung: abhängig vom verwendeten Paket die benutzten Datentypen prüfen**\n",
        "\n",
        "::: {#wrn-logicpandas .callout-warning appearance=\"simple\" collapse=\"false\"}\n",
        "## Achtung Logik!\n",
        "\n",
        "Die logische Abfrage fehlender Werte unterscheidet sich für `None`, `np.nan` und `pd.NA`. \n"
      ],
      "id": "9a824a92"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bool_values = [None, float('NaN'), pd.NA]\n",
        "\n",
        "for element in bool_values:\n",
        "  try:\n",
        "    bool_value = bool(element)\n",
        "  except TypeError as error:\n",
        "      print(error)\n",
        "  else:\n",
        "    print(\"Wahrheitswert von\", element, \"ist\", bool_value)"
      ],
      "id": "bdc1a223",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dies gilt auch für den logischen Identitätsabgleich."
      ],
      "id": "d6cc726f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bool_values = [None, float('NaN'), pd.NA]\n",
        "\n",
        "for element in bool_values:\n",
        "  try:\n",
        "    result = element == element\n",
        "  except TypeError as error:\n",
        "      print(error)\n",
        "  else:\n",
        "    print(\"Identität von\", element, \"ist\", result)"
      ],
      "id": "b827ed7e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: \n",
        "\n",
        "([Pandas Dokumentation](https://pandas.pydata.org/docs/user_guide/missing_data.html))\n",
        "\n",
        "#### Fehlende Werte in Pandas erzeugen, prüfen, finden, ersetzen, löschen\n",
        "Das Modul Pandas wandelt `None` automatisch in `NaN` um. Das Modul Pandas bietet wie das Modul NumPy verschiedene Funktionen, um mit fehlenden Werten zu arbeiten.\n",
        "\n",
        "  - `pd.NA` erzeugt einen fehlenden Wert (Groß- und Kleinschreibung beachten: `pd.na` funktioniert nicht)\n",
        "  \n",
        "  - Die Funktionen `pd.isnull()` und `pd.isna()` prüfen auf einen fehlenden Wert und geben einen Wahrheitswert bzw. ein NumPy-Array mit dtype bool zurück. Die Funktionen `pd.notna()` und `pd.notnull()` prüfen den umgekehrten Fall.\n",
        "\n",
        "  - Die Methode `pd.isna().nonzero()` verwendet die NumPy-Funktion `np.nonzero` und gibt ein Array mit den Indexpositionen der Elemente mit fehlenden Werten zurück.\n",
        "\n",
        "  - `pd.Series.fillna(value = 0)` ersetzt fehlende Werte mit dem im Argument `value` übergebenen Wert. Die Methoden `pd.ffill()` und `pd.bfill()` ersetzen fehlende Werte mit dem letzten bzw. dem nächsten gültigen Wert. Die Methode `pd.Series.interpolate()` ersetzt fehlende Werte durch Interpolation, wofür ein Datentyp definiert sein muss (`dtype = object` funktioniert nicht). Standardmäßig wird linear interpoliert, es stehen aber verschiedene Methoden zur Verfügung (siehe [Pandas Dokumentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html))\n",
        "\n",
        "  - Die Methode `pd.Series.dropna()` gibt eine neue (kürzere) Series ohne fehlende Wert zurück.\n",
        "\n",
        "#### Operationen mit fehlenden Werten\n",
        "Operationen mit `pd.NA` ergeben in der Regel `pd.NA`. Es gibt jedoch einige Ausnahmen:\n"
      ],
      "id": "1320db2b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(pd.NA ** 0)\n",
        "print(1 ** pd.NA)"
      ],
      "id": "e266947a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Methode `pd.Series.sum()` behandelt `pd.NA` als 0, die Methode `pd.Series.prod()` als 1."
      ],
      "id": "29b402d0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(pd.Series([pd.NA]).sum())\n",
        "print(pd.Series([pd.NA]).prod())"
      ],
      "id": "f864ebc5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reduzierende Methoden wie `pd.Series.min()` oder `pd.Series.mean()` sowie zusammenfassende Methoden wie `pd.Series.cumsum()` oder `pd.Series.cumprod()` überspringen `pd.NA`."
      ],
      "id": "39ce05bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(pd.Series([pd.NA]).min())\n",
        "print(pd.Series([pd.NA]).mean())\n",
        "print(pd.Series([pd.NA]).cumsum())\n",
        "print(pd.Series([pd.NA]).cumprod())"
      ],
      "id": "9e4467af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Das Verhalten von Methoden wie `pd.Series.sum()` und von Methoden wie `pd.Series.min()` hat für Datenreihen einen vergleichbaren Effekt, produziert für einzelne Werte jedoch unterschiedliche Ergebnisse.\n",
        "\n",
        "eventuell ergänzen: **Cumulative methods like cumsum() and cumprod() ignore NA values by default preserve them in the result. This behavior can be changed with skipna**\n",
        "\n",
        "https://pandas.pydata.org/docs/user_guide/missing_data.html \n",
        "\n",
        "### Aufgabe fehlende Werte\n",
        "Der Deutsche Wetterdienst misst deutschlandweit verschiedene Wetterdaten.\n",
        "\n",
        "In der Datei produkt_st_stunde_20230831_20240630_01303.txt sind stündliche Stationsmessungen der Solarstrahlung in \n",
        "**Aufgabe von Gianluca: Bestimmen Sie die Kodierung fehlender Werte und ersetzen Sie diese durch `np.nan` bzw. `pd.NA`. Wie viele Werte wurden ersetzt?**  \n",
        "\n",
        "| Spaltenname | Beschreibung |\n",
        "|---|---|\n",
        "| STATIONS_ID | Stationsnummer |\n",
        "| QN_592 | Qualitätsniveau der Daten |\n",
        "| ATMO_LBERG | Stundensumme der atmosphärischen Gegenstrahlung |\n",
        "| FD_LBERG | Stundensumme der diffusen solaren Strahlung |\n",
        "| FG_LBERG | Stundensumme der Globalstrahlung |\n",
        "| SD_LBERG | Stundensumme der Sonnenscheindauer |\n",
        "| ZENIT | Zenitwinkel der Sonne 0 - 180 Grad |\n",
        "\n",
        "::: {.border}\n",
        "Deutscher Wetterdienst. 2024. Stündliche Stationsmessung der Solarstrahlung (global/diffus) und der atmosphärischen Gegenstrahlung für Deutschland. <https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/solar/stundenwerte_ST_01303_row.zip> Die Spalten MESS_DATUM, MESS_DATUM_WOZ und eor wurden entfernt.\n",
        ":::\n",
        "\n",
        "::: {#tip-musterlösungfehlendewerte .callout-tip collapse=\"true\"}\n",
        "## Musterlösung fehlende Werte\n",
        "\n",
        "Mit der Methode `df.info()` ist erkennbar, dass der Datensatz vollständig ist."
      ],
      "id": "69b819aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = \"skript/01-daten/produkt_st_stunde_20230831_20240630_01303.txt\"\n",
        "solar = pd.read_csv(dateipfad, sep = \";\")\n",
        "\n",
        "solar.info()"
      ],
      "id": "63252e6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mit der Methode `df.describe()` wird die deskriptive Statistik für numerische Spalten erstellt.  "
      ],
      "id": "8abbb233"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dateipfad = \"skript/01-daten/produkt_st_stunde_20230831_20240630_01303.txt\"\n",
        "solar = pd.read_csv(dateipfad, sep = \";\")\n",
        "\n",
        "solar.describe()"
      ],
      "id": "927ff8e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drei Spalten weisen als minimalen Wert -999 auf, der inhaltlich nicht sinnvoll ist. Wie oft kommt der Wert -999 in den Spalten vor?\n"
      ],
      "id": "c1f942dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "counting_df = solar[['ATMO_LBERG', 'FD_LBERG', 'FG_LBERG']] == -999\n",
        "print(counting_df.sum())\n",
        "print(\"Summe:\\t\\t \", counting_df.sum().sum())"
      ],
      "id": "4a131fb7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Zeitreihen {#sec-zeitreihen}\n",
        "Marc fragen, was er so macht: Grobe Themen\n",
        "\n",
        "  - pandas, matplotlib, scikit-learn?\n",
        "\n",
        "  - Datenvorbereitung und -bereinigung: Umgang mit fehlenden Werten und Ausreißern\n",
        "\n",
        "  - Trends und Saisonalität\n",
        "\n",
        "  - Autokorrelation?\n",
        "\n",
        "  - Modellierung und Vorhersagen\n",
        "\n",
        "  - Evaluierung von Vorhersagen\n",
        "\n",
        "\n",
        "Welches Datum ist heute? Das hängt vom Kalender ab: Gregorianischer Kalender in Europa, jüdischer Kalender in Israel,  islamischer Kalender, Suriyakati-Kalender in Thailand (hatte ich in der Diss), Astronomische Zählweise (NumPy)\n",
        "\n",
        "Unterschied NumPy und Python wird hier erklärt: https://numpy.org/doc/stable/reference/arrays.datetime.html\n",
        "\n",
        "naive und aware time (aware kennt Zeitzonen, naive nicht): https://numpy.org/doc/stable/reference/arrays.datetime.html#datetime64-conventions-and-assumptions\n",
        "\n",
        "**Fehlersuche und -bereinigung: Kalender prüfen**\n",
        "\n",
        "**Mit Pandas und/oder NumPy SMART-Datensätze einlesen, die gibt es in Deutsch und Englisch mit entsprechendem Datumsformat - siehe Material**\n",
        "\n",
        "### fehlende Werte in Zeitreihen\n",
        "NumPy und Pandas unterstützen `NaT` für `np.datetime64`, `np.timedelta64`\n",
        "\n",
        "  - NumPy: <https://numpy.org/doc/stable/reference/arrays.datetime.html>\n",
        "  \n",
        "  - Pandas: <https://pandas.pydata.org/docs/user_guide/missing_data.html>\n",
        "\n",
        "Achtung Logik\n",
        "```\n",
        "None == None  # noqa: E711\n",
        "Out[14]: True\n",
        "\n",
        "np.nan == np.nan\n",
        "Out[15]: False\n",
        "\n",
        "pd.NaT == pd.NaT\n",
        "Out[16]: False\n",
        "\n",
        "pd.NA == pd.NA\n",
        "Out[17]: <NA>\n",
        "```\n",
        "\n",
        "\n",
        "# Zugriff auf mehrere lokale Dateien: Modul glob\n",
        "Das Modul glob\n",
        "\n",
        "# Datensätze organisieren\n",
        "In diesem Abschnitt werden typische Herausforderungen beim Einlesen strukturierter Datensätze behandelt und Werkzeuge aus den Modulen NumPy und Pandas vorgestellen, um Probleme zu identifizieren und zu beheben. Dazu wird einführend mit tidy data ein grundlegendes Konzept zur Organisation von Datensätzen vorgestellt.\n",
        "\n",
        "## Tidy data\n",
        "**Konzept als Einführung gedacht: Was ist überhaupt das Ziel des Einlesens? (ist aber inkompatibel mit dem Multiindex in Python [und den fehlenden Spaltenbeschriftungen in Numpy])**\n",
        "\n",
        "::: {.border layout=\"[5, 90, 5]\"}\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "“Tidy datasets are all alike, but every messy dataset is messy in its own way.” [@R-for-Data-Science, Kapitel 5 Data tidying]\n",
        "\n",
        "&nbsp;\n",
        "\n",
        ":::\n",
        "\n",
        "Tidy data ist ein System von Hadley Wickham, das dabei hilft, Datensätze in ein aufgeräumtes (tidy) Format zu bringen. Das Aufräumen von Datensätzen ist eine vorbereitende Tätigkeit mit dem Ziel, während der eigentlichen Datenanlyse möglichst wenig Zeit für das Umformen von Datenstrukturen aufwenden zu müssen. Dadurch soll ein größerer Fokus auf den inhaltlichen Aspekt der Datenanalyse ermöglicht werden. [@R-for-Data-Science, Kapitel 5 Data tidying]\n",
        "\n",
        "::: {#imp-tidy-data .callout-important}\n",
        "## tidy data\n",
        "\n",
        ":::: {.border}\n",
        "\n",
        "Das System tidy data besteht aus drei Regeln:\n",
        "\n",
        "1. Jede Variable ist eine Spalte; jede Spalte ist eine Variabe.\n",
        "\n",
        "2. Jede Beobachtung ist eine Zeile; jede Zeile ist eine Beobachtung.\n",
        "\n",
        "3. Jeder Wert ist eine Zelle; jede Zelle ist ein einzelner Wert.\n",
        "\n",
        "[@R-for-Data-Science, Kapitel 5 Data tidying]\n",
        "::::\n",
        ":::\n",
        "\n",
        "Tidy data bezieht sich auf zweidimensionale Datensätze, bietet aber auch darüber hinaus eine Orientierung, um unterschiedlich aufgebaute Datensätze strukturiert einzulesen und für die Datenanalyse vorzubereiten. Tidy data ist kein strikt zu befolgendes Regelwerk. Wenn die Datenanalyse mit einer anderen Struktur leichter durchgeführt werden kann, dann ist das in Ordnung. \n",
        "\n",
        "\n",
        "\n",
        "**Hinweis: `dtype=object` erscheint immer, wenn der Datentyp nicht zugeordnet werden kann. type(object) ist etwas anderes als object.dtype. Erstes bestimmt den Objekttyp, zum Beispiel Liste oder Numpy-Array. Zweiteres bestimmt den Datentyp (Ganzzahl, String). Ich glaube, `dtype=object` ist eine Liste von Zeigern auf Objekte im Speicher. Dazu habe ich aber nur eine [Erklärung auf Stackoverflow](https://stackoverflow.com/a/29877845) gefunden, aber nichts in der Dokumentation.**\n",
        "\n",
        "# Räumliche Daten\n",
        "netCDF mit eigenem Namensschema: dimensions (Name, Datentyp und Länge der Variablen), data variables (die eigentlichen Datensätze), attributes (Informationen über die Daten).\n",
        "\n",
        "# Strategien der Fehlersuche und Bereinigung\n",
        "\n",
        "::: {.border layout=\"[[5, 90, 5], [1], [1]]\"}\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "\"everybody I know has war stories about cleaning up lousy datasets\"  \n",
        "Nicholas J. Cox\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Cox, Nicholas J. 2004: Exploratory Data Mining and Data Cleaning. Book Review 9. In: Journal of Statistical Software 2004, Volume 11. <https://www.jstatsoft.org/article/view/v011b09/30>\n",
        "\n",
        ":::\n",
        "\n",
        "## Werte plausibilisieren\n",
        "1. zulässigen Wertebereich prüfen\n",
        "\n",
        "2. zulässige Werte auf Konsistenz mit fachlicher, ggf. Alltagserfahrung prüfen\n",
        "Ein Beispiel für Alltagserfahrung: <https://www.youtube.com/watch?v=FcxiSwZcPvw> (Anzahl Schuhe usw.)\n",
        "\n",
        "# Spezialformate\n",
        "\n",
        "## HDF, netCDF\n",
        "https://stackoverflow.com/questions/28170623/how-to-read-hdf5-files-in-python\n",
        "\n",
        "## Maskierte Arrays\n",
        "Maskierte Arrays (masked arrays) werden durch das Modul `numpy.ma` bereitgestellt. Maskierte Arrays erlauben es, Werte als ungültig oder fehlend zu markieren, ohne diese zu ersetzen oder zu löschen. Ein maskiertes Array besteht aus drei Elementen. Dies sind erstens ein normales NumPy-Array und zweitens eine Maske. Die Maske hat entweder den Wert `numpy.ma.nomask`, wenn kein Wert ungültig ist oder fehlt. Andernfalls besteht die Maske aus einem Array mit Wahrheitswerten für jedes Element des NumPy-Arrays, ob ein ungültiger/fehlender Wert `True` vorliegt oder nicht `False`. Alle Elemente des NumPy-Arrays, die in der zugehörigen Maske den Wahrheitswert `True` haben, werden im maskierten Array durch eine Zeichenkette ersetzt. Standardmäßig ist dies die Zeichenkette`numpy.ma.masked_print_option = '--'`, die mit dem genannten Argument geändert werden kann. Über die Attribute `.data` und `mask` kann auf das zugrundeliegende NumPy-Array und die Maske zugegriffen werden.\n",
        "\n",
        "**ergänzen: masked_array ist ein Alias von MaskedArray; 16 weitere Methoden ein maskiertes Array zu erzeugen unter: <https://numpy.org/doc/stable/reference/maskedarray.generic.html#constructing-masked-arrays> - einige davon sind wirklich praktisch**\n"
      ],
      "id": "9f62dc5e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy.ma as ma\n",
        "\n",
        "print(f\"NumPy-Array:\\t\\t{np_array_with_none}\") \n",
        "\n",
        "maskiertes_array = ma.masked_array(data = np_array_with_none, mask = [0, 0, 1, 1])\n",
        "print(f\"maskiertes Array:\\t{maskiertes_array}\")\n",
        "\n",
        "print(f\"Daten:\\t\\t\\t\\t{maskiertes_array.data}\")\n",
        "\n",
        "print(f\"Maske:\\t\\t\\t\\t{maskiertes_array.mask}\")"
      ],
      "id": "3b4afcd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Das dritte Element eines maskierten Arrays ist der Füllwert, der beim Anlegen des maskierten Arrays mit dem Argument `fill_value` übergeben werden kann. Der Füllwert wird zunächst nur gespeichert und kann später verwendet werden, um ungültige bzw. fehlende Werte zu ersetzen. Der Füllwert wird mit der `Methode.filled()` aktiviert. Dann wird die Maske auf den Wert `numpy.ma.nomask` gesetzt und ein normales NumPy-Array ausgegeben. **Testen: in Pandas fill_value is not stored in the Int64 object.**\n"
      ],
      "id": "237449e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Anlegen eines maskierten Arrays mit einem Füllwert\n",
        "fill_value_array = ma.masked_array(data = daten_ohne_fehlende_werte[0:4], mask = [0, 0, 1, 1], fill_value = 42) # np_array_with_none\n",
        "\n",
        "print(f\"In der Ausgabe wird ein normales maskiertes Array zurückgegeben:\\n{fill_value_array}\\n\")\n",
        "\n",
        "print(f\"Der Füllwert wird mit der Methode numpy.ma.filled() aktiviert:\\n{fill_value_array.filled()}\\n\")\n",
        "\n",
        "fill_value_array.fill_value = 1.5\n",
        "print(f\"Der Füllwert kann mit np.ma.fill_value = wert geändert werden:\\n{fill_value_array.filled()}\\n\")\n",
        "\n",
        "fill_value_array.fill_value = None\n",
        "print(f\"Der Füllwert None bewirkt den Rückgriff auf einen datentypabhängigen Standardwert:\\n{fill_value_array.filled()}\\n\")\n",
        "\n",
        "print(f\"Das maskierte Array ist weiterhin vorhanden:\\n{fill_value_array}\\n\")"
      ],
      "id": "9dd288e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Standardwert des Arguments `fill_value` ist `None`, mit dem beim Aufrufen der `Methode.filled()` abhängig vom Datentyp ein Standardwert eingesetzt wird.\n",
        "\n",
        "::: {.border}"
      ],
      "id": "c56a8475"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for dt in [np.int32, np.int64, np.float64, np.complex128, np.string_, np.bool_]:\n",
        "\n",
        "  print(dt, \"\\t\\t\", np.ma.array([0, 1], dtype=dt).get_fill_value())"
      ],
      "id": "5ae574b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quelle: <https://numpy.org/doc/stable/reference/maskedarray.baseclass.html#numpy.ma.MaskedArray.fill_value>\n",
        ":::\n",
        "\n",
        "Problemtisch ist die Übergabe des Füllwerts `None`, wenn das initale NumPy-Array None enthält. \n",
        "\n",
        "::: {#wrn-fillvalueandnone .callout-warning appearance=\"simple\" collapse=\"true\"}\n",
        "## Füllwert bei initialem NumPy-Array mit None\n"
      ],
      "id": "acfbce19"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Anlegen eines maskierten Arrays mit Füllwert, initiales NumPy-Array enthält None\n",
        "fill_value_array = ma.masked_array(data = np_array_with_none, mask = [0, 0, 1, 1], fill_value = 42)\n",
        "\n",
        "print(f\"In der Ausgabe wird ein normales maskiertes Array zurückgegeben:\\n{fill_value_array}\\n\")\n",
        "\n",
        "print(f\"Der Füllwert wird mit der Methode numpy.ma.filled() aktiviert:\\n{fill_value_array.filled()}\\n\")\n",
        "\n",
        "fill_value_array.fill_value = 1.5\n",
        "print(f\"Der Füllwert kann mit np.ma.fill_value = wert geändert werden:\\n{fill_value_array.filled()}\\n\")\n",
        "\n",
        "fill_value_array.fill_value = None\n",
        "print(f\"Der Füllwert None bewirkt den Rückgriff auf einen datentypabhängigen Standardwert:\\n{fill_value_array.filled()}\\n\")\n",
        "\n",
        "print(f\"Das maskierte Array ist weiterhin vorhanden:\\n{fill_value_array}\\n\")"
      ],
      "id": "778d88cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "**Fehlersuche und -bereinigung: None ist in NumPy problematisch und sollte manuell kontrolliert und entfernt werden**\n",
        "\n",
        "**Fehlersuche und -bereinigung: Dokumentation lesen, Funktionen können unerwartetes Verhalten zeigen. Arbeiten Sie mit Testdaten, die den einzulesenden Datensatz möglichst gut repräsentieren und arbeiten Sie schrittweise an einer Lösung. Wenden Sie die Lösung auf den echten Datensatz an und vergleichen das Ergbnis zu dem Ergebnis der Testdaten.**\n",
        "\n",
        "\n",
        "**Operationen mit fill_value(): <https://numpy.org/doc/stable/reference/routines.ma.html#filling-a-masked-array>**\n",
        "\n",
        "### Operationen mit maskierten Arrays\n",
        "Wie rechnet man jetzt damit? Der Platzhalter '--' ist vom NoneType, damit kann man nicht rechnen, wenigstens nicht mit mehreren Arrays. Siehe:  \n",
        "<https://numpy.org/doc/stable/reference/maskedarray.generic.html#operations-on-masked-arrays>\n"
      ],
      "id": "3eac98b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(maskiertes_array.sum())\n",
        "\n",
        "print(len(maskiertes_array))\n",
        "\n",
        "print(np_array_with_nan, np_array_with_nan.dtype)\n",
        "\n",
        "print(maskiertes_array, maskiertes_array.dtype)\n",
        "\n",
        "try:\n",
        "  result = np_array_with_nan + maskiertes_array\n",
        "except TypeError as error:\n",
        "  print(\"\\nDie Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(result)\n",
        "\n",
        "try:\n",
        "  result = np_array_with_nan + maskiertes_array.data\n",
        "except TypeError as error:\n",
        "  print(\"\\nDie Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(result)\n",
        "\n",
        "try:\n",
        "  result = np.ma.masked_array(np_array_with_nan) + maskiertes_array.data\n",
        "except TypeError as error:\n",
        "  print(\"\\nDie Eingabe führt zu der Fehlermeldung:\\n\", error)\n",
        "else:\n",
        "  print(result)"
      ],
      "id": "5fde9a4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result of a unary ufunc is masked wherever the input is masked ... or  wherever the corresponding input fall outside the validity domain. (siehe: [Dokumentation](https://numpy.org/doc/stable/reference/maskedarray.generic.html#operations-on-masked-arrays))\n",
        "\n",
        "**In der Doku steht eine Warnung, dass man sich nicht darauf verlassen kann, dass maskierte Werte nicht von Operationen manipuliert werden.**\n",
        "\n",
        "::: {.border layout=\"[[5, 90, 5], [5, 90, 5], [1]]\"}\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Arithmetic and comparison operations are supported by masked arrays. As much as possible, invalid entries of a masked array are not processed, meaning that the corresponding `data` entries *should* be the same before and after the operation.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "&nbsp;\n",
        "\n",
        ":::: {.callout-warning}\n",
        "We need to stress that this behavior may not be systematic, that masked data may be affected by the operation in some cases and therefore users should not rely on this data remaining unchanged.\n",
        "::::\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<https://numpy.org/doc/stable/reference/maskedarray.generic.html#operations-on-masked-arrays>\n",
        "\n",
        ":::\n",
        "\n",
        "**Unklar ist, welche Operationen nicht verlässlich funktionieren.**\n",
        "\n",
        "Das Prinzip: Das Modul `numpy.ma` implementiert die meisten NumPy-Funktionen. Funktionen, die nur einen bestimmten Wertebereich als Eingabe akzeptieren, geben den Wert `masked` zurück, wenn Werte außerhalb des gültigen Bereichs übergeben werden. Ein Beispiel ist die  `ma.log()`.\n"
      ],
      "id": "31ea5620"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ma.log([1, 2, 3, -1])"
      ],
      "id": "787756b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In der Ausgabe wird der \n",
        "Man kann auch Werte maskieren, das ist aber abgesehen von Integer nicht exakt. Für Fließkommazahlen werden auch minimal größere oder kleinere Werte maskiert. Siehe: <https://numpy.org/doc/stable/reference/generated/numpy.ma.masked_values.html>\n",
        "Fehlende Werte in NumPy maskieren\n",
        "<https://numpy.org/doc/stable/reference/maskedarray.html>\n",
        "\n",
        "... können auch mit genfromtxt erzeugt werden\n",
        "`usemask`\n",
        "We may also want to keep track of the occurrence of missing data by constructing a boolean mask, with True entries where data was missing and False otherwise. To do that, we just have to set the optional argument usemask to True (the default is False). The output array will then be a MaskedArray.\n",
        "\n",
        "**Rückkehr des fill_value nach <https://github.com/numpy/numpy/issues/20850#issuecomment-2077856842>**\n",
        "\n",
        "```\n",
        ">>> arr1 = np.ma.masked_equal(arr, value=0)\n",
        ">>> arr1.fill_value\n",
        "0.0\n",
        ">>> arr2 = np.ma.masked_less_equal(arr, value=0)\n",
        ">>> arr2.fill_value\n",
        "1e+20\n",
        "```\n",
        "\n",
        "### Unmasking and hard masks\n",
        "<https://numpy.org/doc/stable/reference/maskedarray.generic.html#unmasking-an-entry>\n",
        "\n",
        "Wie hier <https://github.com/numpy/numpy/issues/20850> erwähnt, nutzt keine der genannten Methoden fill_value und das Verhalten sei inkonstistent: **testen, das Verhalten von fill_value = None ist seltsam, aber works as designed**\n",
        "\n",
        "  - ma.MaskedArray.filled(fill_value=None) uses a.fill_value when fill_value is None\n",
        "  \n",
        "  - a.mask = ma.unmasked ignores a.fill_value\n",
        "  \n",
        "  - ma.fix_invalid(a, mask=False, copy=True, fill_value=None) uses a.fill_value when fill_value is None\n",
        "  \n",
        "  - ma.MaskedArray.tolist(fill_value=None) ignores a.fill_value\n",
        "  \n",
        "  - ma.MaskedArray.tobytes(fill_value=None, order='C') uses a.fill_value when fill_value is None\n",
        "  \n",
        "  - ma.min/ma.max/ma.argmin/ma.argmax ignore a.fill_value\n",
        "\n",
        "# Das Wichtigste (vielleicht als Video)\n",
        "\n",
        "# Lernzielkontrolle\n",
        "\n",
        "  * Kompetenzquiz (ggf. aufklappbarer Callout Block, Textverweis für PDF, polierte Lösungen evntl. via Lumi später entscheiden)\n",
        "\n",
        "  * Übungsaufgaben (kleine Projekte)\n",
        "\n",
        "* Prüfungsaufgaben (ohne Lösungen)"
      ],
      "id": "60986433"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}