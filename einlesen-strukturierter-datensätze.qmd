---
# Metadaten / meta data
title: "Methodenbaustein Einlesen strukturierter Datensätze"
author:
  - Lukas Arnold
  - Simone Arnold
  - Florian Bagemihl
  - Matthias Baitsch
  - Marc Fehr
  - Maik Poetzsch
  - Sebastian Seipel
date: today # "2024-03-05" Jahr-Monat-Tag / year-month-day

## Spracheinstellungen / language settings
lang: de
language:
  de:
    crossref-imp-title: "Definition"
    crossref-imp-prefix: "Definition"
    crossref-lst-title: "Code-Block"
    crossref-lst-prefix: "Code-Block"
    crossref-nte-title: "Beispiel"
    crossref-nte-prefix: "Beispiel"
    crossref-tip-title: "Tipp"
    crossref-tip-prefix: "Tipp"
    crossref-wrn-title: "Hinweis"
    crossref-wrn-prefix: "Hinweis"

## Formatoption / formating options
format:
  html:
    default-image-extension: svg
    code-copy: true # hover is default
#  pdf:
#    cite-method: biblatex
#    biblio-title: Quellen
#    default-image-extension: pdf # Vektorgrafiken werden als PDF eingebunden / vector grafics are embedded as PDF
execute:
  cache: false # remove when document is finished as cache: true can cause issues from time to time

## Inhaltsverzeichnis / table of contents
toc: true
number-sections: true
number-depth: 2

## Bibliographie / bibliography
bibliography: bibliography.bib
biblio-style: authoryear

## Objekteinstellungen / object options
cap-location: bottom
fig-align: center

### Grafiken von R oder Matplotlib / Figures from R or Matplotlib
# Empfehlung von / suggestion from https://r4ds.hadley.nz/quarto#sec-figures
# fig-width: 6
# fig-asp: 0.618
---

::: {.border #Lizenz}

:::: {layout="[20, 80]"}
![](skript/00-bilder/CC-BY.svg)

Bausteine Computergestützter Datenanalyse von Lukas Arnold, Simone Arnold, Florian Bagemihl, Matthias Baitsch, Marc Fehr, Maik Poetzsch und Sebastian Seipel. Methodenbaustein Einlesen strukturierter Datensätze von Maik Poetzsch ist lizensiert unter [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.de). Das Werk ist abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze). Ausgenommen von der Lizenz sind alle Logos und anders gekennzeichneten Inhalte. 2024

::::

Zitiervorschlag

Arnold, Lukas, Simone Arnold, Matthias Baitsch, Marc Fehr, Maik Poetzsch, und Sebastian Seipel. 2024. „Bausteine Computergestützter Datenanalyse. Methodenbaustein Einlesen strukturierter Datensätze“. <https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze>.

BibTeX-Vorlage

```
@misc{BCD-m-einlesen-strukturierter-datensätze-2024,
 title={Bausteine Computergestützter Datenanalyse. Methodenbaustein Einlesen strukturierter Datensätze},
 author={Arnold, Lukas and Arnold, Simone and Baitsch, Matthias and Fehr, Marc and Poetzsch, Maik and Seipel, Sebastian},
 year={2024},
 url={https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze}} 
```

:::

{{< pagebreak >}}

{{< include _voraussetzungen.md >}}

{{< include _lernziele.md >}}

# Einleitung

2016 stellte eine Studie fest, dass ein Fünftel aller wissenschaftlichen Artikel im Bereich der Genetik auf der Grundlage von durch die Tabellenkalkulation Excel verfälschten Daten durchgeführt wurde [@Ziemann-2016]. Genbezeichnungen wie "MARCH1" wurden fälschlicherweise in ein Datumsformat umgewandelt. 2021 wurde diese Schätzung des Anteils betroffener Arbeiten sogar auf 30 Prozent angehoben. ([heise online](https://www.heise.de/news/Excel-wandelt-Genbezeichnungen-in-Datumsangaben-um-Problem-groesser-als-gedacht-6165902.html))

Am Beginn der computergestützten Datenanalyse steht das Einlesen von Daten aus Dateien. In der Praxis ist das Einlesen von Daten alles andere als trivial. Daten werden in einer Vielzahl von Dateiformaten gespeichert. Deshalb ist es in der Datenanalyse erforderlich, mit verschiedenen Dateiformaten umgehen zu können: mit wenigen Kilobyte großen Textdateien, offenen und proprietären Formaten gängiger Büroanwendungen und mehreren hundert Megabyte großen Dateien in speziell für den Austausch wissenschaftlicher Daten entwickelten Formaten. Programmiersprachen wie Python und R bringen verschiedene Werkzeuge zum Lesen, Bearbeiten und Speichern von verschiedenen Dateiformaten mit, die durch spezialisierte Pakete ergänzt werden können.

Die praktischen Herausforderungen der Datenanalyse beschränken sich jedoch nicht nur auf technische Aspekte. Oftmals bereitet der innere Aufbau von Datensätzen die größten Schwierigkeiten. Ein wichtiger Bestandteil des Einlesens strukturierter Datensätze besteht deshalb darin, Fehler im Datensatz zu suchen und ggf. zu bereinigen. Dasu und Johnson schreiben: 

::: {.border layout="[5, 90, 5]"}

&nbsp;

"Unfortunately, the data set is usually dirty, composed of many tables, and has unknown properties. Before any results can be produced, the data must be cleaned and explored—often a long and
difficult task. [...] In our experience, the tasks of exploratory data mining and data cleaning constitute 80% of the effort that determines 80% of the value of the ultimate data
mining results." (@Dasu-Johnson-2003, S. ix)

&nbsp;

:::

&nbsp;

Das Einlesen strukturierter Datensätze umfasst somit den gesamten Prozess des technischen Zugriffs auf Dateien, der Organisation, Fehlersuche und -korrektur sowie des Abspeicherns der Daten in einer für die weitere Bearbeitung geeigneten Form.

# Grundlagen: Merkmale von Datensätzen
Bevor wir uns mit den praktischen Herausforderungen des Einlesens strukturierter Datensätze beschäftigten, werden zunächst einige Merkmale von Datensätzen behandelt, um ein grundlegendes Verständnis der Begrifflichkeiten zu schaffen und den Umgang der in der Basis von Python enthaltenen Werkzeuge zu vermitteln.

::: {#imp-Datensatz .callout-important}
## Datensatz

Ein Datensatz ist eine Sammlung zusammengehöriger Daten. Datensätze enthalten einer oder mehreren Variablen zugeordnete Werte. Jeder Datensatz besitzt ein technisches Format, eine Struktur, mindestens eine Variable und mindestens einen Wert.

:::

## Technisches Format
Das technische Format eines Datensatzes gibt vor, mit welchen Mitteln Daten eingelesen, bearbeitet und gespeichert werden können. Einige Beispiele sind:

  - Druckerzeugnis, z. B. Telefonbuch: manuelles Ablesen von Name und Telefonnummer, irreversible Bearbeitung per Stift
  
  - Lochkarte, z. B. Parkschein: Lesegerät erkennt Lochung und gewährt eine Freistunde, irreversible Bearbeitung mit Stanzgerät
  
  - Textdatei, z. B. Einwohnerzahl nach Bundesländern: Kann mit einer Vielzahl von Computerprogrammen wie Texteditor, Tabellenkalkulationsprogramm oder Programmierumgebung eingelesen, bearbeitet und gespeichert werden.
  
  - Hierarchical Data Format HDF5, z. B. räumliche Daten zur Blitzdichte: benötigt spezialisierte Programme oder Pakete

## Struktur
Datensätze speichern Daten in einer definierten n-dimensionalen Struktur.

::: {.border}
![n-dimensionale Datensätze](skript/00-bilder/slicing_mf_mp.png){fig-alt="Dargestellt sind von links nach rechts ein-, zwei- und dreidimensionale Blockstrukturen, die Datensätze repräsentieren. Die Teilgrafiken werden in den folgenden Abschnitten wiederverwendet und dabei auch näher beschrieben."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). 2024
:::

### Eindimensionale Datensätze
Die einfachste Form sind eindimensionale Datensätze, die in einer **Liste** Werte einer einzigen Variablen zuordnen. Eindimensionale Datensätze verfügen lediglich über eine Achse: den Index, über den Elemente angesprochen werden können.

::: {.border}

![eindimensionale Datensätze](skript/00-bilder/eindimensionaler-datensatz-slicing-mf-mp.png){width="50%" fig-alt="Dargestellt ist ein in fünf Blöcke unterteilter Streifen, der einen eindimensionalen Datensatz repräsentiert. Die Blöcke sind entlang der 0. Achse von links nach rechts mit 0 bis 4 beschriftet. Von Block Null aus geht ein blauer Pfeil zu Block drei, der blau markiert ist."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024
:::

&nbsp;

Beispiele eindimensionaler Datensätze sind ein Einkaufszettel oder die Urliste eines Würfelexperiments. Über den Index kann beispielsweise das Würfelergebnis an der Indexposition 2 ausgegeben werden.

``` {python}
print( *( Augen := [6, 2, 1, 2] ) )

print(f"Das Würfelergebnis an Indexposition 2 lautet: {Augen[2]}")
```


### Eindimensionale Daten einlesen mit Python
Maya und Hans haben je sechs Mal einen Würfel geworfen und ihre Wurfergebnisse in einer .txt-Datei protokolliert. Wir wollen mit die Dateien mit Python auswerten, um zu bestimmen, wer von beiden in Summe die höchste Augenzahl erreicht hat.

| Daten | Dateiname |
|---|------|
| Würfelergebnisse Maya | dice-maya.txt |
| Würfelergebnisse Hans | dice-hans.txt|

&nbsp;

{{< include _dateien-einlesen-mit-python.md >}}

### Zweidimensionale Datensätze
Zweidimensionale Datensätze organisieren Werte in einer aus Zeilen und Spalten bestehenden **Matrix** oder einem **Dataframe**.  Matritzen enthalten nur einen Datentyp (bspw. Zahlen), Dataframes können unterschiedliche Datentypen enthalten (bspw. Zahlen und Wahrheitswerte).

::: {.border}
![zweidimensionaler Datensatz](skript/00-bilder/zweidimensionaler-datensatz-slicing-mf-mp.png){width="45%" fig-alt="Dargestellt ist ein zweidimensionaler Block, der einen zweidimensionalen Datensatz repräsentiert. Pfeile repräsentieren die zwei Achsen. Die nullte Achse entspricht der Länge (von oben nach unten) und die erste Achse der Breite des Datensatzes."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024
:::

&nbsp;

Die meisten Datensätze sind zweidimensional. Typischerweise entspricht jede Spalte einer **Variablen** und jede Zeile einer **Beobachtung**. Variablen speichern alle Werte eines Merkmals, zum Beispiel des Würfelergebnisses. Beobachtungen speichern alle Werte, die für eine Beobachtungseinheit gemessen wurden, z. B. für eine Person. [@Wickham-2014, S. 3]

``` {python}
import pandas as pd

messung1 = pd.DataFrame({'Name': ['Hans', 'Elke', 'Jean', 'Maya'], 'Geburtstag': ['26.02.', '14.03.', '30.12.', '07.09.'], 'Würfelfarbe': ['rosa', 'rosa', 'blau', 'gelb'], 'Summe Augen': [17, 12, 8, 23]})

messung1
```

&nbsp;

Über die Angabe der Indizes entlang der 0. und der 1. Achse kann die Summe der gewürfelten Augen einer Person ausgegeben werden. 

``` {python}

print(f"Jean würfelte {messung1.iloc[2, 3]} Augen")
```

Es ist aber auch möglich, zunächst eine Spalte auszuwählen und dann wie bei einem eindimensionalen Datensatz den Wert an einer Indexposition aufzurufen.

``` {python}

print(f"Jean würfelte {messung1['Summe Augen'][2]} Augen")
```

### long- und wide-Format
Zweidimensionale Datensätze werden zumeist in einer aus Zeilen und Spalten bestehenden Matrix dargestellt. Den zeilenweise eingetragenen Beobachtungen werden Werte für die in den Spalten organisierten Variablen zugeordnet. Diese Art Daten darzustellen, wird wide-Format genannt: Mit jeder zusätzlich gemessenen Variablen wird der Datensatz breiter.

Eine andere Art Daten zu organisieren und über Daten nachzudenken, ist die Darstellung im long-Format. Einige Programme und Pakete erfordern Daten im long-Format oder profitieren zumindest davon beispielsweise bei der Erstellung von Grafiken. Schauen wir uns zunächst noch einmal den Datensatz messung1 im wide-Format an. Welche Beobachtungseinheiten gibt es? Welche Variablen wurden für diese erhoben?

``` {python}
#| echo: false

messung1
```

&nbsp;

Vermutlich werden Sie davon ausgehen, dass die Beobachtungseinheiten Hans, Elke, Jean und Maya sind und die Variablen Geburtstag, Würfelfarbe und Summe Augen. Es ist aber auch denkbar, dass die Beobachtungseinheit Person mit 0, 1, 2 und 3 kodiert wurde (dem Zeilenindex des Datensatzes) und die Spalte Name ebenfalls eine der erhobenen Variablen ist. Ebenso könnte es nur zwei Variablen, Würfelfarbe und Summe Augen, geben, während die Spalten Name und Geburtstag die beobachteten Personen kodieren. Stellen Sie sich vor, eine zweite Person mit dem Namen Hans hätte auch gewürfelt. Dann könnten die Würfelergebnisse der Personen mit dem Namen Hans nur über den Geburtstag am 26.02. oder 11.11. korrekt zugeordnet werden.

``` {python}
messung1 = pd.DataFrame({'Name': ['Hans', 'Elke', 'Jean', 'Maya', 'Hans'], 'Geburtstag': ['26.02.', '14.03.', '30.12.', '07.09.', '11.11.'], 'Würfelfarbe': ['rosa', 'rosa', 'blau', 'gelb', 'rosa'], 'Summe Augen': [12, 17, 8, 23, 7]})

messung1
```

&nbsp;

Das long-Format macht diese Überlegungen explizit, indem identifizierende Variablen (identification variables, kurz: id vars) und gemessene Variablen (measure variables, kurz: measure vars oder value vars) unterschieden werden. Die Transformation eines Datensatzes aus dem wide-Format ins long-Format wird melting (schmelzen) genannt. Das Modul Pandas bietet die Funktion `pd.melt(frame, id_vars = None)`. Diese erwartet einen DataFrame. Im optionalen Argument `id_vars` wird angegeben, welche Spalten die identifizierenden Variablen sind.

``` {python}

messung1_long = pd.melt(messung1, id_vars = ['Name', 'Geburtstag'])

messung1_long
```

&nbsp;

Im long-Format werden die gemessenen Variablen in der Spalte variable aufgeführt und deren Wert in der Spalte value eingetragen. Mit jeder zusätzlich erhobenen Variablen wird der Datensatz länger.

Wenn Sie die Unterscheidung von identifizierenden und gemessenen Variablen zu Ende denken, kann der Variablenname selbst als eine identifizierende Variable für den Wert in der Spalte value aufgefasst werden. Ein Datensatz kann als eine Struktur verstanden werden, die genau eine gemessene Variable, nämlich value, und eine Anzahl identifizierender Variablen besitzt. Dies kann im long-Format wie folgt dargestellt werden.

``` {python}
#| output: false

messung1_all_id = pd.melt(messung1, id_vars = ['Name', 'Geburtstag', 'Würfelfarbe'])

messung1_all_id

```

::: {layout="[70, 30]"}
``` {python}
#| echo: false

messung1_all_id = pd.melt(messung1, id_vars = ['Name', 'Geburtstag', 'Würfelfarbe'])

messung1_all_id

```

![](skript/00-bilder/5f489ffabc91dec1ec2192dc4e993e00.jpg){width="90%"} 

<!-- wow kommt wieder weg ;-) -->

::: 

Auch der umgekehrte Fall ist möglich: Werden beim melting keine id_vars angegeben, werden alle Spalten als gemessene Variablen behandelt.

``` {python}

messung1_no_id = pd.melt(messung1)

messung1_no_id

```

&nbsp;

Die Umkehroperation zum melting wird casting (gießen) oder pivoting (schwenken) genannt. Dabei wird ein im long-Format vorliegender Datensatz in das wide-Format konvertiert. Die Pandas Funktion `pd.pivot(data, columns, index)` nimmt einen melted DataFrame entgegen und konveriert diesen aus den einzigartigen Werten in columns (= Spaltennamen des DataFrame im wide-Format) und den einzigartigen Werten in index (= Zeilenindex des DataFrame im wide-Format). Wird der Funktion keine Spalte für index übergeben, wird der bestehende Index des melted DataFrame verwendet (der mit 20 Zeilen natürlich viel zu lang ist.) Da das Objekt messung1_no_id keine geeignete Indexspalte besitzt, muss diese vor dem casting erzeugt werden. Dies ist mit der Methode `messung1_no_id.groupby('variable').cumcount()` möglich, die die Anzahl jeder Ausprägung in der übergebenen Spalte bei 0 beginnend durchzählt. (Ein direktes Ersetzen des Index ist auf diese Weise nicht möglich, da der Index des an `pd.pivot(data, columns, index)` übergebenen DataFrames keine Doppelungen enthalten darf.)

``` {python}
# pd.pivot() benötigt einen Index oder benutzt den bestehenden Index, des melted_df, der zu lang ist
# Deshalb eine zusätzliche Spalte in messung1_no_id einfügen
## einfach: messung1_no_id['new_index'] = list(range(0, 5)) * 4 
## allgemein: messung1_no_id['new_index'] = messung1_no_id.groupby('variable').cumcount()

# Spalte new_index einfügen
messung1_no_id['new_index'] = messung1_no_id.groupby('variable').cumcount()
print (f"Der Datensatz im long-Format mit zusätzlicher Spalte new_index:\n{messung1_no_id}")

# casting
messung1_cast = pd.pivot(messung1_no_id, index = 'new_index', columns = 'variable', values = 'value')
print(f"\nDer Datensatz im wide-Format:\n{messung1_cast}")
```

Das Ergebnis entspricht noch nicht dem ursprünglichen Datensatz im wide-Format. Um das Ausgangsformat wiederherzustellen, müssen die Spalten in die ursprüngliche Reihenfolge gebracht sowie der Index und dessen Beschriftung zurückgesetzt werden.

```{python}

# Spalten anordnen, Index zurücksetzen
messung1_cast = messung1_cast[['Name', 'Geburtstag', 'Würfelfarbe', 'Summe Augen']]
messung1_cast.reset_index(drop = True, inplace = True)
messung1_cast.rename_axis(None, axis = 1, inplace = True)

print(f"\nDer Datensatz im wide-Format mit zurückgesetztem Index:\n\n{messung1_cast}")

```

### Übung: zweidimensionale Datensätze
Oben wurde das Objekt messung1_long mit dem Befehl `messung1_long = pd.melt(messung1, id_vars = ['Name', 'Geburtstag'])` angelegt.  
**Benutzen Sie die Funktion** `df.cast()`, **um den Datensatz messung1 wieder ins wide-Format zu transformieren.**

``` {python}
#| echo: false

messung1_long
```


:::{#tip-pivoting .callout-tip collapse="true"}
## Musterlösung zweidimensionale Datensätze

``` {python}

# Spalte new_index einfügen
messung1_long['new_index'] = messung1_long.groupby('variable').cumcount()

# casting
messung1_long_cast = pd.pivot(messung1_long, index = 'new_index', columns = 'variable', values = 'value')

# Spalten anordnen, Index zurücksetzen
messung1_long_cast = messung1_cast[['Name', 'Geburtstag', 'Würfelfarbe', 'Summe Augen']]
messung1_long_cast.reset_index(drop = True, inplace = True)
messung1_long_cast.rename_axis(None, axis = 1, inplace = True)

messung1_long_cast

```


:::

### Drei- und mehrdimensionale Datensätze
Drei- oder mehrdimensionale Datensätze organisieren komplexe Datenstrukturen in sogenannten **Arrays**. Beispielsweise ist eine Excel-Datei mit mehreren Arbeitsblättern für jährlich erhobene Umfragedaten ein 3-dimensionales Array (Arbeitsblätter, Zeilen, Spalten). Insbesondere Sensordaten liegen häufig in mehrdimensionalen Strukturen vor. 

::: {.border}

![dreidimensionale Datensätze](skript/00-bilder/dreidimensionaler-datensatz-slicing-mf-mp.png){width="50%" fig-alt="Dargestellt ist ein dreidimensionaler Block, der einen dreidimensionalen Datensatz repräsentiert. Pfeile repräsentieren die drei Achsen. Die nullte Achse entspricht der Tiefe, die erste Achse der Länge (von oben nach unten) und die zweite Achse der Breite des Datensatzes."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024

:::

&nbsp;

**Hier könnte man eine Liste aus einer .JPEG in ein NumPy-Array umwandeln und als Bild darstellen.**  
**optional: Exkurs JSON**

Für drei- und mehrdimensionale Datenstrukturen werden häufig spezialisierte Datenformate verwendet, die in den Folgenden Abschnitten werden. Dies hat unter anderem den Grund, dass so leichter verschiedene Datentypen verarbeitet und mit [@sec-metadaten] dokumentiert werden können. Beispielsweise kann der Wert "1" eine Zahl, den Monat Januar, ein Zeichen, einen Wahrheitswert oder die Ausprägung einer kategorialen Variablen (eines Faktors [**Faktor in R und Kategorie in [Pandas](https://pandas.pydata.org/docs/user_guide/categorical.html)**]) repräsentieren. 

# Datentyp {#sec-datentyp}

Unterstützte Datentypen sind ein wichtiges Merkmal von Datensätzen. Datentypen bestimmen darüber, welche Operationen zulässig sind (z. B. datetime-Operationen). 

  - unterstützte Datentypen in Python von Simone bzw. von der Python Doku...

NumPy-Array: numerische Datentypen --> hier reicht ein Querverweis auf den w-NumPy

Pandas.DataFrame: Vielzahl von Datentypen --> hier reicht ein Querverweis auf den w-Pandas
numerisch, character, category, boolean, datetime usw. ... 

Ein wichtiger Datentyp: nichts bzw. fehlende Werte

Korrektes Verwalten von Datentypen hilft unter anderem Fehler zu vermeiden. [0, 1, 2] ist eine korrekte numerische Liste, enthielte als Liste von Wahrheitswerten jedoch einen Datenfehler. 

  - typischer Fehler beim Einlesen von Datensätzen: Datum wird nicht erkannt, numerische Spalten werden wegen fehlender Werte falsch eingelesen. 

 
# Metadaten {#sec-metadaten}
gute Überleitung: Man muss wie gesagt wissen, wie 

# fehlende Werte {#sec-missing}
Unterstützen nicht alle Datensatzformate explizit, ist aber eine wichtige Funktion

nix, NA, NaN, --, -1

masked Arrays

eindimensionaler Datensatz: Urliste von Ergebnissen eines Münzwurfs.
Woraus besteht ein Datensatz?

Dazu gehört die Trennung von Rohdaten, Metadaten, Grafiken und anderer gestalterische Elemente. 

disziplinäre Konventionen und persönliche Vorlieben (z. B. zur Kennzeichnung fehlender oder ungültiger Werte)
ein "NA" führt leicht dazu, dass ein numerischer Datensatz als Zeichenkette erkannt wird.


# Strategien der Fehlersuche und Bereinigung

## Fehlersuche
::: {.border layout="[5, 90, 5]"}

&nbsp;

“Tidy datasets are all alike, but every messy dataset is messy in its own way.” [@R-for-Data-Science, Kapitel 5 Data tidying]

&nbsp;

:::

## Fehlerbereinigung
::: {.border layout="[[5, 90, 5], [1], [1]]"}

&nbsp;

"everybody I know has war stories about cleaning up lousy datasets"  
Nicholas J. Cox

&nbsp;

&nbsp; 

Cox, Nicholas J. 2004: Exploratory Data Mining and Data Cleaning. Book Review 9. In: Journal of Statistical Software 2004, Volume 11. <https://www.jstatsoft.org/article/view/v011b09/30>

:::

# Programme
https://www.heise.de/news/Excel-wandelt-Genbezeichnungen-in-Datumsangaben-um-Problem-groesser-als-gedacht-6165902.html

# Pfade
Dateipfad feststellen (lokal, im Internet), durch Verzeichnisse navigieren 

  * slash / und backslash nach Betriebssystem (Win, Linux, Mac) und Programmiersprache (Python und R)

* Inhalt (gerne abwechslungsreich gestalten)

  * Theorie

  * Beispiele

  * Übungen

# Das Wichtigste (vielleicht als Video)

# Lernzielkontrolle

  * Kompetenzquiz (ggf. aufklappbarer Callout Block, Textverweis für PDF, polierte Lösungen evntl. via Lumi später entscheiden)

  * Übungsaufgaben (kleine Projekte)

* Prüfungsaufgaben (ohne Lösungen)
